const devopsData={topics:[{id:"docker",name:"Docker",icon:"üê≥",color:"#0db7ed",flashcards:[{term:"Container",definition:"A lightweight, standalone, executable package that includes everything needed to run a piece of software: code, runtime, system tools, libraries, and settings."},{term:"Docker Image",definition:"A read-only template with instructions for creating a Docker container. Images are built from Dockerfiles and can be shared via registries."},{term:"Dockerfile",definition:"A text file containing instructions to build a Docker image. It defines the base image, dependencies, and commands to run."},{term:"Docker Compose",definition:"A tool for defining and running multi-container Docker applications using a YAML file to configure services, networks, and volumes."},{term:"Docker Hub",definition:"A cloud-based registry service for storing, sharing, and distributing Docker images. It hosts both public and private repositories."},{term:"Docker Volume",definition:"A mechanism for persisting data generated and used by Docker containers. Volumes are stored outside the container filesystem."},{term:"Docker Network",definition:"A virtual network that allows containers to communicate with each other and external networks in isolated or connected configurations."},{term:"Docker Swarm",definition:"Docker's native clustering and orchestration solution for managing a cluster of Docker engines as a single virtual system."},{term:"Container Registry",definition:"A repository for storing and distributing container images. Examples include Docker Hub, Amazon ECR, and Google Container Registry."},{term:"Multi-stage Build",definition:"A Dockerfile technique using multiple FROM statements to create smaller, more efficient final images by copying only necessary artifacts."},{term:"Docker Layer",definition:"Each instruction in a Dockerfile creates a layer. Layers are cached and reused to speed up builds and reduce storage."},{term:"Entrypoint vs CMD",definition:"ENTRYPOINT sets the main executable; CMD provides default arguments. ENTRYPOINT is harder to override than CMD."},{term:"Docker Context",definition:"The set of files and directories sent to the Docker daemon when building an image. Optimizing context size improves build performance."},{term:"Docker Buildx",definition:"An extended build command that supports multi-platform builds, build caching, and other advanced features."},{term:"Container Runtime",definition:"The software responsible for running containers. Docker uses containerd as its default runtime, which manages container lifecycle."},{term:"Docker Healthcheck",definition:"A Dockerfile instruction that tells Docker how to test a container to check that it is still working properly."},{term:"Docker Secrets",definition:"A secure way to pass sensitive data to containers in Swarm mode, stored encrypted until needed by a service."},{term:"Docker Overlay Network",definition:"A distributed network that enables communication between containers running on different Docker hosts."},{term:"containerd",definition:"An industry-standard container runtime that manages the complete container lifecycle including image transfer, storage, and execution."},{term:"Docker Desktop",definition:"An application for Mac and Windows that provides a Docker development environment with built-in Kubernetes."},{term:"Docker Engine",definition:"The core technology that creates and runs containers. Consists of a server daemon, REST API, and CLI client."},{term:"Docker Scout",definition:"A security tool that analyzes container images for vulnerabilities and provides remediation recommendations."},{term:"Docker Init",definition:"A command that helps bootstrap a project with Docker by generating Dockerfile, compose.yaml, and .dockerignore files."},{term:"COPY vs ADD",definition:"COPY only copies local files; ADD can also extract archives and download URLs. COPY is preferred for simplicity."},{term:"Docker Daemon",definition:"The background service (dockerd) that manages Docker objects like images, containers, networks, and volumes."},{term:"Bridge Network",definition:"The default network driver that creates a private internal network on the host for containers to communicate."},{term:"Host Network",definition:"A network mode where the container shares the host's networking namespace, using the host's IP directly."},{term:"None Network",definition:"A network mode that disables all networking for a container, providing complete network isolation."},{term:"Docker Restart Policy",definition:"Controls whether containers automatically restart when they exit or when Docker daemon restarts. Options: no, on-failure, always, unless-stopped."},{term:"Docker Logs",definition:"Commands and drivers for viewing and managing container output. Supports various logging drivers like json-file, syslog, fluentd."},{term:"Docker Stats",definition:"Displays real-time resource usage statistics for containers including CPU, memory, network I/O, and block I/O."},{term:"Docker Tag",definition:"A label applied to an image to identify different versions. Format: registry/repository:tag."},{term:"Docker Push",definition:"Uploads a local image to a remote registry, sharing it for deployment or with other users."},{term:"Docker Pull",definition:"Downloads an image from a registry to the local machine for use in creating containers."},{term:"Docker Commit",definition:"Creates a new image from a container's changes. Useful for debugging but Dockerfiles are preferred for reproducibility."},{term:"Docker Save/Load",definition:"Save exports an image to a tar archive; Load imports it back. Used for offline image transfer."},{term:"Docker Export/Import",definition:"Export creates a tarball of container filesystem; Import creates an image from it. Flattens layers."},{term:".dockerignore",definition:"A file listing patterns of files and directories to exclude from the build context, reducing build time and image size."},{term:"ARG Instruction",definition:"Defines build-time variables that can be passed with --build-arg. Not available in running container."},{term:"ENV Instruction",definition:"Sets environment variables that persist in the image and are available to running containers."},{term:"WORKDIR Instruction",definition:"Sets the working directory for subsequent RUN, CMD, ENTRYPOINT, COPY, and ADD instructions."},{term:"EXPOSE Instruction",definition:"Documents which ports the container listens on. Does not actually publish ports; use -p flag for that."},{term:"USER Instruction",definition:"Sets the user and optionally the group to use when running the image and for subsequent instructions."},{term:"LABEL Instruction",definition:"Adds metadata to an image as key-value pairs, useful for organization, licensing, and automation."},{term:"SHELL Instruction",definition:"Overrides the default shell used for the shell form of commands in Dockerfile."},{term:"STOPSIGNAL Instruction",definition:"Sets the system call signal that will be sent to the container to exit, default is SIGTERM."},{term:"ONBUILD Instruction",definition:"Adds trigger instructions to an image that execute when the image is used as a base for another build."},{term:"Docker Prune",definition:"Commands to remove unused data: docker system prune, docker image prune, docker container prune, docker volume prune."},{term:"Docker Manifest",definition:"A list of images for different platforms. Enables pulling the correct image for the host architecture automatically."},{term:"Docker Content Trust",definition:"A security feature that uses digital signatures to verify the integrity and publisher of Docker images."},{term:"Docker Bench",definition:"A security script that checks for common best-practices around deploying Docker containers in production."},{term:"Bind Mount",definition:"Mounts a file or directory from the host machine into a container. Changes are reflected bidirectionally."},{term:"tmpfs Mount",definition:"A temporary filesystem mount stored in host memory only. Data is lost when container stops."},{term:"Named Volume",definition:"A Docker-managed volume with a specific name, easier to reference and manage than anonymous volumes."},{term:"Anonymous Volume",definition:"A volume without a specified name, automatically created and harder to reference after container removal."},{term:"Docker Build Cache",definition:"Mechanism that reuses unchanged layers from previous builds to speed up subsequent builds."},{term:"BuildKit",definition:"A modern build subsystem with parallel build stages, better caching, and new Dockerfile features."},{term:"Docker Scan",definition:"Scans local images for vulnerabilities using Snyk, providing a CVE report and remediation advice."},{term:"Docker Extensions",definition:"Third-party tools that add functionality to Docker Desktop, accessible through the Extensions Marketplace."},{term:"Docker Contexts",definition:"Named configurations that contain information about Docker endpoints, allowing switching between different Docker hosts."},{term:"Docker Checkpoint",definition:"Experimental feature to save the state of a running container for later restoration (using CRIU)."},{term:"Resource Constraints",definition:"Limits for CPU, memory, and other resources that can be set on containers to prevent resource exhaustion."},{term:"Rootless Mode",definition:"Running Docker daemon and containers without root privileges for enhanced security."},{term:"Docker Plugins",definition:"Extensions that add capabilities like network drivers, volume drivers, or authorization to Docker."},{term:"Docker API",definition:"RESTful API that allows programmatic interaction with the Docker daemon for automation and tooling."},{term:"Docker SDK",definition:"Libraries for interacting with the Docker API in various programming languages like Python and Go."},{term:"Docker in Docker (DinD)",definition:"Running Docker inside a Docker container, commonly used in CI/CD pipelines for building images."},{term:"Docker Socket",definition:"Unix socket at /var/run/docker.sock that allows communication with the Docker daemon."},{term:"Docker Proxy",definition:"Built-in proxy that handles port forwarding from host to containers for published ports."},{term:"Scratch Image",definition:"An explicitly empty image, useful as a base for creating minimal images containing only your application."},{term:"Alpine Linux",definition:"A minimal Linux distribution popular as a Docker base image due to its small size (~5MB)."},{term:"Distroless Images",definition:"Container images that contain only the application and its runtime dependencies, without a shell or package manager."},{term:"Image Digest",definition:"A SHA256 hash that uniquely identifies an image, more precise than tags which can be moved."},{term:"Docker Attach",definition:"Connects to a running container's standard input, output, and error streams."},{term:"Docker Wait",definition:"Blocks until a container stops, then prints its exit code. Useful in scripts."},{term:"Docker Top",definition:"Displays the running processes inside a container, similar to the Linux top command."},{term:"Docker Diff",definition:"Shows changes made to the container's filesystem compared to its image."},{term:"Docker History",definition:"Shows the history of an image including each layer, its size, and the command that created it."},{term:"Docker Events",definition:"Streams real-time events from the Docker daemon, useful for monitoring and automation."},{term:"Docker Port",definition:"Lists port mappings for a container, showing which host ports map to container ports."},{term:"Docker Rename",definition:"Changes the name of an existing container without affecting its configuration."},{term:"Docker Update",definition:"Dynamically updates container resource limits without stopping it."},{term:"Docker Pause/Unpause",definition:"Suspends and resumes all processes in a container using cgroups freezer."},{term:"Docker Kill",definition:"Sends a signal (default SIGKILL) to a container's main process, immediately stopping it."},{term:"Docker Stop",definition:"Gracefully stops a container by sending SIGTERM, then SIGKILL after timeout."},{term:"OCI Standard",definition:"Open Container Initiative - industry standards for container runtime and image format."},{term:"Podman",definition:"A daemonless container engine compatible with Docker commands, uses fork/exec model instead."},{term:"Docker Machine",definition:"Legacy tool for provisioning Docker hosts on virtual machines, now largely replaced by Docker Desktop."}],commands:[{command:"docker build -t myapp .",description:"Build an image from Dockerfile"},{command:"docker run -d -p 8080:80 myapp",description:"Run container in background with port mapping"},{command:"docker ps -a",description:"List all containers (running and stopped)"},{command:"docker logs -f container_id",description:"Follow container logs in real-time"},{command:"docker exec -it container_id bash",description:"Execute interactive bash in container"},{command:"docker-compose up -d",description:"Start all services in background"},{command:"docker system prune -a",description:"Remove all unused images and containers"},{command:"docker inspect container_id",description:"View detailed container information"},{command:"docker network create mynetwork",description:"Create a custom network"},{command:"docker volume ls",description:"List all volumes"},{command:"docker images",description:"List all local images"},{command:"docker rmi image_id",description:"Remove an image"},{command:"docker rm container_id",description:"Remove a stopped container"},{command:"docker stop $(docker ps -q)",description:"Stop all running containers"},{command:"docker pull nginx:latest",description:"Download an image from registry"},{command:"docker push myrepo/myapp:v1",description:"Upload image to registry"},{command:"docker tag myapp myrepo/myapp:v1",description:"Tag an image for pushing"},{command:"docker login",description:"Authenticate with Docker registry"},{command:"docker cp file.txt container:/path/",description:"Copy files to/from container"},{command:"docker stats",description:"Show live resource usage of containers"},{command:"docker top container_id",description:"Display running processes in container"},{command:"docker diff container_id",description:"Show filesystem changes in container"},{command:"docker history image_id",description:"Show image layer history"},{command:"docker save -o myapp.tar myapp",description:"Export image to tar file"},{command:"docker load -i myapp.tar",description:"Import image from tar file"},{command:"docker export container > fs.tar",description:"Export container filesystem"},{command:"docker import fs.tar newimage",description:"Create image from tarball"},{command:"docker run --rm -it alpine sh",description:"Run interactive container and remove on exit"},{command:"docker run -v /host/path:/container/path",description:"Mount host directory as volume"},{command:"docker run --name mycontainer nginx",description:"Run container with specific name"},{command:"docker run -e VAR=value myapp",description:"Set environment variable"},{command:"docker run --env-file .env myapp",description:"Load environment from file"},{command:"docker run --network mynetwork myapp",description:"Connect container to network"},{command:"docker run --restart always myapp",description:"Set restart policy"},{command:"docker run --memory 512m myapp",description:"Limit container memory"},{command:"docker run --cpus 0.5 myapp",description:"Limit CPU usage"},{command:"docker network ls",description:"List all networks"},{command:"docker network inspect bridge",description:"View network details"},{command:"docker network connect net1 container",description:"Connect container to network"},{command:"docker network disconnect net1 container",description:"Disconnect from network"},{command:"docker volume create myvolume",description:"Create a named volume"},{command:"docker volume rm myvolume",description:"Remove a volume"},{command:"docker volume inspect myvolume",description:"View volume details"},{command:"docker-compose down -v",description:"Stop and remove containers, networks, volumes"},{command:"docker-compose logs -f",description:"Follow logs of all services"},{command:"docker-compose build --no-cache",description:"Rebuild without using cache"},{command:"docker-compose exec service bash",description:"Run command in service container"},{command:"docker-compose ps",description:"List containers for project"},{command:"docker buildx build --platform linux/amd64,linux/arm64 -t myapp .",description:"Multi-platform build"},{command:"docker scan myapp",description:"Scan image for vulnerabilities"}],quiz:[{question:"What is the main purpose of a Dockerfile?",options:["To run containers","To define instructions for building an image","To manage container networks","To store container data"],correct:1},{question:"Which command is used to build a Docker image?",options:["docker run","docker build","docker create","docker start"],correct:1},{question:"What does Docker Compose primarily help with?",options:["Building single containers","Managing multi-container applications","Storing images","Monitoring containers"],correct:1},{question:"Where is data stored when using Docker volumes?",options:["Inside the container","In the image layers","Outside the container filesystem","In Docker Hub"],correct:2},{question:"What is a multi-stage build used for?",options:["Running multiple containers","Creating smaller final images","Managing multiple registries","Building on multiple platforms"],correct:1},{question:"Which is Docker's native orchestration tool?",options:["Kubernetes","Docker Swarm","Mesos","Nomad"],correct:1},{question:"What does the -d flag do in docker run?",options:["Deletes the container after exit","Runs in detached/background mode","Enables debug mode","Downloads the image"],correct:1},{question:"What is Docker Buildx used for?",options:["Building Docker Compose files","Multi-platform builds","Container networking","Image scanning"],correct:1},{question:"Which network driver enables cross-host communication?",options:["bridge","host","overlay","none"],correct:2},{question:"How are Docker Secrets stored?",options:["Plain text files","Environment variables","Encrypted at rest","In Dockerfile"],correct:2},{question:"What does the --rm flag do in docker run?",options:["Removes the image after use","Automatically removes container when it exits","Removes all other containers","Resets memory usage"],correct:1},{question:"What is the purpose of .dockerignore?",options:["Ignore containers","Exclude files from build context","Ignore network issues","Skip health checks"],correct:1},{question:"Which instruction sets environment variables that persist in running containers?",options:["ARG","ENV","SET","VAR"],correct:1},{question:"What is the difference between COPY and ADD?",options:["No difference","ADD can extract archives and download URLs","COPY is slower","ADD is deprecated"],correct:1},{question:"What is containerd?",options:["A container name","A container registry","An industry-standard container runtime","A Docker command"],correct:2},{question:"What does docker system prune do?",options:["Updates Docker","Removes unused data","Prunes container processes","Backs up system"],correct:1},{question:"What is a bind mount?",options:["Type of network","Mounts host file/directory into container","Encryption method","Volume driver"],correct:1},{question:"What is the scratch image?",options:["Damaged image","An explicitly empty image for minimal builds","Testing image","Debug image"],correct:1},{question:"What is Docker rootless mode?",options:["Running without root privileges","Running without network","Minimal container mode","Read-only mode"],correct:0},{question:"What does docker logs -f do?",options:["Filters logs","Follows/streams logs in real-time","Formats logs","Finds specific logs"],correct:1},{question:"What is an image digest?",options:["Image description","SHA256 hash uniquely identifying an image","Image size","Build number"],correct:1},{question:"What is DinD (Docker in Docker)?",options:["Docker installation","Running Docker inside a Docker container","Docker network mode","Docker daemon type"],correct:1},{question:"What is Alpine Linux commonly used for in Docker?",options:["Database hosting","Minimal base image (~5MB)","Web servers only","Windows containers"],correct:1},{question:"What does docker pause do?",options:["Stops containers","Suspends container processes using cgroups freezer","Pauses image download","Delays builds"],correct:1},{question:"What is the Docker socket path?",options:["/etc/docker","/var/run/docker.sock","/home/docker","/tmp/docker"],correct:1},{question:"What is BuildKit?",options:["Build tool kit","Modern build subsystem with improved caching","Docker extension","Container kit"],correct:1},{question:"What does EXPOSE instruction do in Dockerfile?",options:["Opens firewall ports","Documents which ports container listens on","Publishes ports automatically","Exposes secrets"],correct:1},{question:"What is a tmpfs mount?",options:["Permanent storage","Temporary filesystem stored in memory","Tarball filesystem","Template filesystem"],correct:1},{question:"What command shows running processes in a container?",options:["docker ps","docker top","docker proc","docker list"],correct:1},{question:"How do you limit container memory?",options:["--mem-limit","--memory","--max-mem","--ram"],correct:1},{question:"What is Docker Content Trust?",options:["License agreement","Digital signature verification for images","Backup system","Access control"],correct:1},{question:"What is the OCI?",options:["Online Container Index","Open Container Initiative - industry standards","Original Container Image","Official Container Installer"],correct:1},{question:"What command shows image layer history?",options:["docker layers","docker history","docker show","docker info"],correct:1},{question:"What is the default network driver?",options:["host","bridge","overlay","macvlan"],correct:1},{question:"What does docker cp do?",options:["Copies containers","Copies files between container and host","Copies images","Copies networks"],correct:1},{question:"What is a distroless image?",options:["Image without distribution","Image with only app and runtime, no shell","Uncompressed image","Raw image"],correct:1},{question:"What restart policy restarts unless manually stopped?",options:["always","on-failure","unless-stopped","never"],correct:2},{question:"What does docker diff show?",options:["Image differences","Container filesystem changes","Version differences","Config differences"],correct:1},{question:"What is docker-compose down -v used for?",options:["Downloads volumes","Stops and removes containers, networks, and volumes","Verifies down","Verbose down"],correct:1},{question:"What is Podman?",options:["Docker plugin","Daemonless container engine compatible with Docker","Pod manager only","Docker GUI"],correct:1}],codebase:[{title:"Basic Dockerfile",filename:"Dockerfile",language:"dockerfile",description:"A simple Dockerfile for a Node.js application with multi-stage build",code:'# Build stage\nFROM node:20-alpine AS builder\nWORKDIR /app\nCOPY package*.json ./\nRUN npm ci --only=production\n\n# Production stage\nFROM node:20-alpine\nWORKDIR /app\nCOPY --from=builder /app/node_modules ./node_modules\nCOPY . .\nEXPOSE 3000\nUSER node\nCMD ["node", "server.js"]'},{title:"Docker Compose - Full Stack",filename:"docker-compose.yml",language:"yaml",description:"Complete docker-compose setup with web app, database, and Redis cache",code:'version: \'3.8\'\n\nservices:\n  web:\n    build: .\n    ports:\n      - "3000:3000"\n    environment:\n      - DATABASE_URL=postgres://user:pass@db:5432/myapp\n      - REDIS_URL=redis://cache:6379\n    depends_on:\n      - db\n      - cache\n    restart: unless-stopped\n    healthcheck:\n      test: ["CMD", "curl", "-f", "http://localhost:3000/health"]\n      interval: 30s\n      timeout: 10s\n      retries: 3\n\n  db:\n    image: postgres:15-alpine\n    volumes:\n      - postgres_data:/var/lib/postgresql/data\n    environment:\n      POSTGRES_USER: user\n      POSTGRES_PASSWORD: pass\n      POSTGRES_DB: myapp\n    restart: unless-stopped\n\n  cache:\n    image: redis:7-alpine\n    volumes:\n      - redis_data:/data\n    restart: unless-stopped\n\nvolumes:\n  postgres_data:\n  redis_data:\n\nnetworks:\n  default:\n    name: myapp-network'},{title:"Python Flask Dockerfile",filename:"Dockerfile.python",language:"dockerfile",description:"Production-ready Dockerfile for Python Flask applications",code:'FROM python:3.11-slim\n\n# Set environment variables\nENV PYTHONDONTWRITEBYTECODE=1\nENV PYTHONUNBUFFERED=1\n\nWORKDIR /app\n\n# Install dependencies\nCOPY requirements.txt .\nRUN pip install --no-cache-dir -r requirements.txt\n\n# Copy application\nCOPY . .\n\n# Create non-root user\nRUN adduser --disabled-password --gecos \'\' appuser\nUSER appuser\n\nEXPOSE 5000\nCMD ["gunicorn", "--bind", "0.0.0.0:5000", "app:app"]'},{title:".dockerignore",filename:".dockerignore",language:"plaintext",description:"Essential dockerignore file to optimize build context",code:"# Dependencies\nnode_modules\n__pycache__\n*.pyc\n.venv\nvenv\n\n# Git\n.git\n.gitignore\n\n# IDE\n.vscode\n.idea\n*.swp\n\n# Build artifacts\ndist\nbuild\n*.log\n\n# Environment files\n.env\n.env.local\n*.env\n\n# Docker\nDockerfile*\ndocker-compose*\n.docker\n\n# Tests\ntest\ntests\ncoverage\n.pytest_cache\n\n# Documentation\nREADME.md\ndocs"},{title:"Multi-Architecture Build Script",filename:"build-multi-arch.sh",language:"bash",description:"Build and push multi-platform Docker images using buildx",code:'#!/bin/bash\nset -e\n\nIMAGE_NAME="myregistry/myapp"\nVERSION=${1:-latest}\n\n# Create and use buildx builder\ndocker buildx create --name multiarch --use 2>/dev/null || docker buildx use multiarch\n\n# Build and push for multiple platforms\ndocker buildx build \\\n  --platform linux/amd64,linux/arm64 \\\n  --tag ${IMAGE_NAME}:${VERSION} \\\n  --tag ${IMAGE_NAME}:latest \\\n  --push \\\n  --cache-from type=registry,ref=${IMAGE_NAME}:cache \\\n  --cache-to type=registry,ref=${IMAGE_NAME}:cache,mode=max \\\n  .\n\necho "Successfully built and pushed ${IMAGE_NAME}:${VERSION}"'},{title:"Docker Health Check Script",filename:"healthcheck.sh",language:"bash",description:"Custom health check script for Docker containers",code:'#!/bin/bash\n# healthcheck.sh - Custom health check for Docker container\n\n# Check if main process is running\nif ! pgrep -x "node" > /dev/null; then\n    echo "Main process not running"\n    exit 1\nfi\n\n# Check HTTP endpoint\nresponse=$(curl -sf http://localhost:3000/health)\nif [ $? -ne 0 ]; then\n    echo "HTTP health check failed"\n    exit 1\nfi\n\n# Check database connection\nif ! node -e "require(\'./db\').ping()" 2>/dev/null; then\n    echo "Database connection failed"\n    exit 1\nfi\n\necho "Health check passed"\nexit 0'}]},{id:"kubernetes",name:"Kubernetes",icon:"‚ò∏Ô∏è",color:"#326ce5",flashcards:[{term:"Pod",definition:"The smallest deployable unit in Kubernetes, consisting of one or more containers that share storage, network, and specifications for how to run."},{term:"Deployment",definition:"A Kubernetes resource that manages a replicated application, handling updates and rollbacks for Pods and ReplicaSets."},{term:"Service",definition:"An abstract way to expose an application running on a set of Pods as a network service with a stable IP and DNS name."},{term:"Namespace",definition:"A mechanism for isolating groups of resources within a single cluster. Useful for separating environments or teams."},{term:"ConfigMap",definition:"An API object used to store non-confidential configuration data in key-value pairs that can be consumed by Pods."},{term:"Secret",definition:"An object that stores sensitive data like passwords, tokens, or keys. Secrets are base64 encoded and can be mounted as volumes."},{term:"Ingress",definition:"An API object that manages external access to services in a cluster, typically HTTP, providing load balancing and SSL termination."},{term:"ReplicaSet",definition:"A resource that maintains a stable set of replica Pods running at any given time, ensuring the specified number of identical Pods."},{term:"StatefulSet",definition:"A workload API object for managing stateful applications with stable, unique network identifiers and persistent storage."},{term:"DaemonSet",definition:"Ensures that all (or some) nodes run a copy of a Pod. Useful for node-level operations like log collection or monitoring."},{term:"Helm",definition:"A package manager for Kubernetes that helps define, install, and upgrade complex Kubernetes applications using charts."},{term:"kubectl",definition:"The command-line tool for communicating with a Kubernetes cluster's control plane using the Kubernetes API."},{term:"Node",definition:"A worker machine in Kubernetes that runs containerized applications. Each node contains the services necessary to run Pods."},{term:"Cluster",definition:"A set of nodes that run containerized applications managed by Kubernetes, including both control plane and worker nodes."},{term:"PersistentVolume",definition:"A piece of storage in the cluster that has been provisioned by an administrator or dynamically using Storage Classes."},{term:"PersistentVolumeClaim",definition:"A request for storage by a user. PVCs consume PV resources and can specify size and access modes."},{term:"StorageClass",definition:"Provides a way to describe different classes of storage, enabling dynamic provisioning of persistent volumes."},{term:"Control Plane",definition:"The container orchestration layer that manages the worker nodes and pods, including API server, scheduler, and controller manager."},{term:"API Server",definition:"The front-end for the Kubernetes control plane, handling REST operations and serving as the gateway to the cluster."},{term:"etcd",definition:"A consistent and highly-available key-value store used as Kubernetes backing store for all cluster data."},{term:"Scheduler",definition:"Watches for newly created Pods with no assigned node and selects a node for them to run on."},{term:"Controller Manager",definition:"Runs controller processes like node controller, replication controller, and endpoint controller."},{term:"kubelet",definition:"An agent that runs on each node ensuring containers are running in a Pod as expected."},{term:"kube-proxy",definition:"A network proxy that runs on each node, implementing part of the Kubernetes Service concept."},{term:"Container Runtime",definition:"Software responsible for running containers. Kubernetes supports containerd, CRI-O, and other CRI implementations."},{term:"CRI",definition:"Container Runtime Interface - a plugin interface enabling kubelet to use different container runtimes."},{term:"CNI",definition:"Container Network Interface - a specification for configuring network interfaces in Linux containers."},{term:"CSI",definition:"Container Storage Interface - a standard for exposing storage systems to containerized workloads."},{term:"Horizontal Pod Autoscaler",definition:"Automatically scales the number of Pod replicas based on observed CPU utilization or other metrics."},{term:"Vertical Pod Autoscaler",definition:'Automatically adjusts CPU and memory reservations for pods to help "right size" applications.'},{term:"Cluster Autoscaler",definition:"Automatically adjusts the size of the Kubernetes cluster when pods fail to schedule or nodes are underutilized."},{term:"Job",definition:"Creates one or more Pods and ensures a specified number successfully terminate. Used for batch processing."},{term:"CronJob",definition:"Creates Jobs on a repeating schedule, similar to cron in Unix systems."},{term:"NetworkPolicy",definition:"Specifies how groups of pods are allowed to communicate with each other and other network endpoints."},{term:"ResourceQuota",definition:"Provides constraints that limit aggregate resource consumption per namespace."},{term:"LimitRange",definition:"Sets default, minimum, and maximum resource usage constraints for pods in a namespace."},{term:"ServiceAccount",definition:"Provides an identity for processes running in a Pod, used for authentication to the API server."},{term:"RBAC",definition:"Role-Based Access Control - method for regulating access to resources based on roles."},{term:"Role",definition:"Sets permissions within a namespace. Contains rules that represent a set of permissions."},{term:"ClusterRole",definition:"Sets permissions cluster-wide. Can be used for cluster-scoped resources or across namespaces."},{term:"RoleBinding",definition:"Grants permissions defined in a Role to a user or set of users within a namespace."},{term:"ClusterRoleBinding",definition:"Grants permissions defined in a ClusterRole across the entire cluster."},{term:"Pod Security Policy",definition:"Cluster-level resource that controls security sensitive aspects of pod specification (deprecated, replaced by Pod Security Admission)."},{term:"Pod Security Admission",definition:"Built-in admission controller that enforces Pod Security Standards at the namespace level."},{term:"Admission Controller",definition:"Intercepts requests to the API server prior to persistence, for validation or mutation."},{term:"ValidatingWebhook",definition:"Validates requests to the API server and can reject requests that don't meet criteria."},{term:"MutatingWebhook",definition:"Modifies requests to the API server before persistence, such as injecting sidecars."},{term:"Custom Resource Definition",definition:"Extends the Kubernetes API with custom resources that can be managed like built-in resources."},{term:"Operator Pattern",definition:"A method of packaging and running Kubernetes-native applications using custom resources and controllers."},{term:"Sidecar Container",definition:"A container that runs alongside the main container in a pod to provide supporting functionality."},{term:"Init Container",definition:"Specialized containers that run before app containers in a Pod, useful for setup tasks."},{term:"Ephemeral Container",definition:"Temporary containers added to running pods for debugging purposes."},{term:"Taint",definition:"Applied to nodes to repel pods that don't tolerate the taint, controlling pod placement."},{term:"Toleration",definition:"Applied to pods to allow scheduling on nodes with matching taints."},{term:"Node Selector",definition:"A simple pod scheduling constraint that matches node labels."},{term:"Node Affinity",definition:"More expressive node selection constraints, supporting soft and hard requirements."},{term:"Pod Affinity",definition:"Schedules pods based on labels of pods already running on nodes."},{term:"Pod Anti-Affinity",definition:"Prevents pods from being scheduled on nodes where certain pods are running."},{term:"Priority Class",definition:"Defines a mapping from a priority class name to the integer priority value."},{term:"Pod Disruption Budget",definition:"Limits the number of pods that can be down simultaneously during voluntary disruptions."},{term:"Liveness Probe",definition:"Checks if a container is running. If it fails, kubelet kills and restarts the container."},{term:"Readiness Probe",definition:"Checks if a container is ready to serve traffic. Failing pods are removed from Service endpoints."},{term:"Startup Probe",definition:"Checks if the application has started. Disables liveness/readiness probes until it succeeds."},{term:"ClusterIP",definition:"Default service type that exposes the service on an internal IP, only reachable within the cluster."},{term:"NodePort",definition:"Exposes the service on each node's IP at a static port, accessible from outside the cluster."},{term:"LoadBalancer",definition:"Exposes the service externally using a cloud provider's load balancer."},{term:"ExternalName",definition:"Maps a service to a DNS name, returning a CNAME record."},{term:"Headless Service",definition:"A service without a cluster IP, used for stateful sets or service discovery."},{term:"Ingress Controller",definition:"A component that implements the Ingress resource, such as nginx-ingress or traefik."},{term:"Gateway API",definition:"Next-generation Kubernetes API for service networking, more expressive than Ingress."},{term:"Service Mesh",definition:"Infrastructure layer handling service-to-service communication with features like encryption and observability."},{term:"Istio",definition:"Popular service mesh providing traffic management, security, and observability features."},{term:"Linkerd",definition:"Lightweight service mesh focused on simplicity and performance."},{term:"Kustomize",definition:"Template-free configuration customization for Kubernetes, built into kubectl."},{term:"Helm Chart",definition:"A package containing all resource definitions needed to run an application in Kubernetes."},{term:"Values File",definition:"YAML file containing default configuration values for a Helm chart."},{term:"kubeconfig",definition:"Configuration file used by kubectl to access clusters, containing cluster, user, and context info."},{term:"Context",definition:"A named tuple of cluster, user, and namespace used in kubeconfig for cluster access."}],commands:[{command:"kubectl get pods",description:"List all pods in current namespace"},{command:"kubectl get pods -A",description:"List pods in all namespaces"},{command:"kubectl get nodes",description:"List all nodes in the cluster"},{command:"kubectl describe pod <name>",description:"Show detailed pod information"},{command:"kubectl logs <pod>",description:"View pod logs"},{command:"kubectl logs -f <pod>",description:"Follow/stream pod logs"},{command:"kubectl exec -it <pod> -- bash",description:"Execute interactive shell in pod"},{command:"kubectl apply -f manifest.yaml",description:"Apply configuration from file"},{command:"kubectl delete -f manifest.yaml",description:"Delete resources from file"},{command:"kubectl create namespace <name>",description:"Create a new namespace"},{command:"kubectl get svc",description:"List all services"},{command:"kubectl get deploy",description:"List all deployments"},{command:"kubectl get ingress",description:"List all ingresses"},{command:"kubectl get configmaps",description:"List all ConfigMaps"},{command:"kubectl get secrets",description:"List all Secrets"},{command:"kubectl get pv",description:"List PersistentVolumes"},{command:"kubectl get pvc",description:"List PersistentVolumeClaims"},{command:"kubectl scale deploy <name> --replicas=3",description:"Scale deployment to 3 replicas"},{command:"kubectl rollout status deploy/<name>",description:"Check rollout status"},{command:"kubectl rollout undo deploy/<name>",description:"Rollback deployment"},{command:"kubectl rollout history deploy/<name>",description:"View rollout history"},{command:"kubectl port-forward pod/<name> 8080:80",description:"Forward local port to pod"},{command:"kubectl top pods",description:"Show pod resource usage"},{command:"kubectl top nodes",description:"Show node resource usage"},{command:"kubectl run nginx --image=nginx",description:"Create and run a pod"},{command:"kubectl expose deploy <name> --port=80",description:"Create service for deployment"},{command:"kubectl edit deploy <name>",description:"Edit deployment in editor"},{command:"kubectl patch deploy <name> -p '{\"spec\":...}'",description:"Patch a resource"},{command:"kubectl label pod <name> app=web",description:"Add label to pod"},{command:'kubectl annotate pod <name> desc="value"',description:"Add annotation"},{command:"kubectl taint nodes <node> key=val:NoSchedule",description:"Add taint to node"},{command:"kubectl cordon <node>",description:"Mark node as unschedulable"},{command:"kubectl drain <node>",description:"Safely evict pods from node"},{command:"kubectl uncordon <node>",description:"Mark node as schedulable"},{command:"kubectl get events --sort-by=.lastTimestamp",description:"View sorted events"},{command:"kubectl config get-contexts",description:"List all contexts"},{command:"kubectl config use-context <name>",description:"Switch context"},{command:"kubectl config current-context",description:"Show current context"},{command:"kubectl cluster-info",description:"Display cluster info"},{command:"kubectl api-resources",description:"List all API resources"},{command:"kubectl explain pod.spec",description:"Show resource documentation"},{command:"kubectl get pods -o yaml",description:"Output in YAML format"},{command:"kubectl get pods -o json",description:"Output in JSON format"},{command:"kubectl get pods -l app=nginx",description:"Filter by label"},{command:"kubectl get pods --field-selector status.phase=Running",description:"Filter by field"},{command:"kubectl diff -f manifest.yaml",description:"Show diff before apply"},{command:"kubectl auth can-i create pods",description:"Check permissions"},{command:"kubectl debug pod/<name> -it --image=busybox",description:"Debug pod with ephemeral container"},{command:"helm install release chart/",description:"Install Helm chart"},{command:"helm upgrade release chart/",description:"Upgrade Helm release"},{command:"helm list",description:"List Helm releases"},{command:"helm uninstall release",description:"Uninstall Helm release"}],quiz:[{question:"What is the smallest deployable unit in Kubernetes?",options:["Container","Pod","Deployment","Node"],correct:1},{question:"Which resource provides a stable network endpoint for Pods?",options:["Deployment","ConfigMap","Service","Ingress"],correct:2},{question:"What is the purpose of a Namespace?",options:["Store secrets","Isolate resources within a cluster","Manage external traffic","Store configuration"],correct:1},{question:"Which Kubernetes object is used to store sensitive data?",options:["ConfigMap","Secret","Volume","Service"],correct:1},{question:"What does a DaemonSet ensure?",options:["All pods have unique names","A pod runs on all/some nodes","External access to services","Data persistence"],correct:1},{question:"What is Helm used for in Kubernetes?",options:["Container runtime","Package management","Network policies","Log collection"],correct:1},{question:"Which command-line tool is used to interact with Kubernetes?",options:["docker","kubectl","helm","kubeadm"],correct:1},{question:"What workload is best for stateful applications?",options:["Deployment","ReplicaSet","StatefulSet","DaemonSet"],correct:2},{question:"What is etcd used for in Kubernetes?",options:["Container runtime","Key-value store for cluster data","Load balancing","Pod scheduling"],correct:1},{question:"What does the kubelet do?",options:["Schedules pods","Runs containers in pods","Manages API requests","Stores configuration"],correct:1},{question:"What is a PersistentVolumeClaim?",options:["Storage request by user","Pod definition","Network policy","Container image"],correct:0},{question:"Which service type exposes a static port on each node?",options:["ClusterIP","NodePort","LoadBalancer","ExternalName"],correct:1},{question:"What does HPA stand for?",options:["High Performance API","Horizontal Pod Autoscaler","Host Pod Access","HTTP Proxy Agent"],correct:1},{question:"What is a CronJob used for?",options:["Continuous deployment","Scheduled tasks","Persistent storage","Network policies"],correct:1},{question:"What is an Init Container?",options:["Container for initialization","Main application container","Sidecar container","Debug container"],correct:0},{question:"What does RBAC stand for?",options:["Resource Based Access Control","Role Based Access Control","Runtime Based Access Control","Request Based Access Control"],correct:1},{question:"What is a Taint used for?",options:["Marking pods","Repelling pods from nodes","Encrypting data","Logging"],correct:1},{question:"What probe checks if a container is ready to serve traffic?",options:["Liveness","Readiness","Startup","Health"],correct:1},{question:"What is a Custom Resource Definition (CRD)?",options:["Custom pod type","API extension mechanism","Network resource","Storage definition"],correct:1},{question:"What is the Operator pattern?",options:["Manual operations","Packaging apps with custom controllers","Network operations","Storage operations"],correct:1},{question:"What does kubectl apply do?",options:["Deletes resources","Creates/updates resources from file","Shows logs","Lists pods"],correct:1},{question:"What is a Sidecar container?",options:["Main container","Supporting container in same pod","Init container","Debug container"],correct:1},{question:"What is Pod Affinity used for?",options:["Pod deletion","Scheduling based on other pods","Pod scaling","Pod networking"],correct:1},{question:"What is a Headless Service?",options:["Service without pods","Service without ClusterIP","Service without port","Service without selector"],correct:1},{question:"What controls voluntary disruption limits?",options:["ResourceQuota","LimitRange","Pod Disruption Budget","Priority Class"],correct:2},{question:"What does kubectl drain do?",options:["Adds pods","Safely evicts pods from node","Deletes node","Creates namespace"],correct:1},{question:"What is Kustomize used for?",options:["Container building","Configuration customization","Monitoring","Logging"],correct:1},{question:"What is an Ingress Controller?",options:["API component","Implementation of Ingress resource","Storage controller","Pod controller"],correct:1},{question:"What is the CNI?",options:["Container Name Interface","Container Network Interface","Cluster Node Integration","Control Network Interface"],correct:1},{question:"What does kubectl port-forward do?",options:["Opens firewall","Forwards local port to pod","Exposes service","Creates ingress"],correct:1},{question:"What is a Service Mesh?",options:["Network cables","Service-to-service communication layer","Container mesh","Pod mesh"],correct:1},{question:"What is Istio?",options:["Container runtime","Service mesh","Package manager","Monitoring tool"],correct:1},{question:"What stores cluster, user, and context info?",options:["ConfigMap","Secret","kubeconfig","Deployment"],correct:2},{question:"What does kubectl scale do?",options:["Weighs pods","Changes replica count","Measures resources","Scales nodes"],correct:1},{question:"What is the Control Plane?",options:["Worker nodes","Orchestration layer managing cluster","Network layer","Storage layer"],correct:1},{question:"What does kubectl rollout undo do?",options:["Deletes deployment","Rolls back to previous version","Pauses rollout","Restarts pods"],correct:1},{question:"What is a ValidatingWebhook?",options:["Creates resources","Validates API requests","Updates deployments","Deletes pods"],correct:1},{question:"What provides cluster-wide permissions?",options:["Role","ClusterRole","RoleBinding","ServiceAccount"],correct:1},{question:"What does kubectl top show?",options:["Pod images","Resource usage","Pod labels","Node addresses"],correct:1},{question:"What is Gateway API?",options:["API gateway","Next-gen service networking API","Admin API","Storage API"],correct:1}],codebase:[{title:"Deployment Manifest",filename:"deployment.yaml",language:"yaml",description:"Complete Kubernetes Deployment with resource limits, probes, and affinity",code:'apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: myapp\n  labels:\n    app: myapp\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: myapp\n  template:\n    metadata:\n      labels:\n        app: myapp\n    spec:\n      containers:\n      - name: myapp\n        image: myregistry/myapp:v1.0.0\n        ports:\n        - containerPort: 8080\n        resources:\n          requests:\n            memory: "128Mi"\n            cpu: "100m"\n          limits:\n            memory: "256Mi"\n            cpu: "500m"\n        livenessProbe:\n          httpGet:\n            path: /health\n            port: 8080\n          initialDelaySeconds: 30\n          periodSeconds: 10\n        readinessProbe:\n          httpGet:\n            path: /ready\n            port: 8080\n          initialDelaySeconds: 5\n          periodSeconds: 5\n        env:\n        - name: DATABASE_URL\n          valueFrom:\n            secretKeyRef:\n              name: app-secrets\n              key: database-url\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 100\n            podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app: myapp\n              topologyKey: kubernetes.io/hostname'},{title:"Service & Ingress",filename:"service-ingress.yaml",language:"yaml",description:"ClusterIP Service with Ingress for external access",code:"apiVersion: v1\nkind: Service\nmetadata:\n  name: myapp-service\nspec:\n  selector:\n    app: myapp\n  ports:\n  - port: 80\n    targetPort: 8080\n  type: ClusterIP\n---\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: myapp-ingress\n  annotations:\n    nginx.ingress.kubernetes.io/rewrite-target: /\n    cert-manager.io/cluster-issuer: letsencrypt-prod\nspec:\n  ingressClassName: nginx\n  tls:\n  - hosts:\n    - myapp.example.com\n    secretName: myapp-tls\n  rules:\n  - host: myapp.example.com\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: myapp-service\n            port:\n              number: 80"},{title:"ConfigMap & Secret",filename:"config-secret.yaml",language:"yaml",description:"ConfigMap for app config and Secret for sensitive data",code:'apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: app-config\ndata:\n  LOG_LEVEL: "info"\n  FEATURE_FLAGS: "newUI=true,darkMode=false"\n  config.json: |\n    {\n      "apiEndpoint": "https://api.example.com",\n      "timeout": 30,\n      "retries": 3\n    }\n---\napiVersion: v1\nkind: Secret\nmetadata:\n  name: app-secrets\ntype: Opaque\nstringData:\n  database-url: "postgres://user:password@db:5432/myapp"\n  api-key: "your-secret-api-key"\n  jwt-secret: "super-secret-jwt-key"'},{title:"HorizontalPodAutoscaler",filename:"hpa.yaml",language:"yaml",description:"Auto-scale pods based on CPU and memory metrics",code:"apiVersion: autoscaling/v2\nkind: HorizontalPodAutoscaler\nmetadata:\n  name: myapp-hpa\nspec:\n  scaleTargetRef:\n    apiVersion: apps/v1\n    kind: Deployment\n    name: myapp\n  minReplicas: 2\n  maxReplicas: 10\n  metrics:\n  - type: Resource\n    resource:\n      name: cpu\n      target:\n        type: Utilization\n        averageUtilization: 70\n  - type: Resource\n    resource:\n      name: memory\n      target:\n        type: Utilization\n        averageUtilization: 80\n  behavior:\n    scaleDown:\n      stabilizationWindowSeconds: 300\n      policies:\n      - type: Percent\n        value: 10\n        periodSeconds: 60\n    scaleUp:\n      stabilizationWindowSeconds: 0\n      policies:\n      - type: Percent\n        value: 100\n        periodSeconds: 15"},{title:"Helm Chart values.yaml",filename:"values.yaml",language:"yaml",description:"Helm chart values for customizable deployments",code:'# Default values for myapp\nreplicaCount: 3\n\nimage:\n  repository: myregistry/myapp\n  tag: "v1.0.0"\n  pullPolicy: IfNotPresent\n\nservice:\n  type: ClusterIP\n  port: 80\n\ningress:\n  enabled: true\n  className: nginx\n  annotations:\n    cert-manager.io/cluster-issuer: letsencrypt-prod\n  hosts:\n    - host: myapp.example.com\n      paths:\n        - path: /\n          pathType: Prefix\n  tls:\n    - secretName: myapp-tls\n      hosts:\n        - myapp.example.com\n\nresources:\n  limits:\n    cpu: 500m\n    memory: 256Mi\n  requests:\n    cpu: 100m\n    memory: 128Mi\n\nautoscaling:\n  enabled: true\n  minReplicas: 2\n  maxReplicas: 10\n  targetCPUUtilizationPercentage: 70\n\nnodeSelector: {}\ntolerations: []\naffinity: {}'}]},{id:"cicd",name:"CI/CD",icon:"üîÑ",color:"#f97316",flashcards:[{term:"Continuous Integration",definition:"A practice where developers frequently merge code changes into a central repository, triggering automated builds and tests."},{term:"Continuous Delivery",definition:"An extension of CI that automatically prepares code changes for release to production, requiring manual approval for deployment."},{term:"Continuous Deployment",definition:"Takes CD further by automatically deploying every change that passes all stages of the production pipeline without manual intervention."},{term:"Pipeline",definition:"A set of automated processes that allows developers to reliably and efficiently compile, build, test, and deploy code."},{term:"Build Artifact",definition:"The output of the build process, such as compiled code, Docker images, or packages ready for deployment."},{term:"GitHub Actions",definition:"A CI/CD platform integrated with GitHub that automates workflows like building, testing, and deploying code based on events."},{term:"Jenkins",definition:"An open-source automation server that enables developers to build, test, and deploy applications with plugins and Jenkinsfiles."},{term:"GitLab CI/CD",definition:"A built-in continuous integration and delivery tool in GitLab, configured using a .gitlab-ci.yml file in the repository."},{term:"Blue-Green Deployment",definition:"A deployment strategy using two identical production environments to reduce downtime and risk during releases."},{term:"Canary Deployment",definition:"A deployment strategy that gradually rolls out changes to a small subset of users before releasing to the entire infrastructure."},{term:"Rolling Deployment",definition:"Incrementally updates instances with new versions, replacing old versions one at a time to minimize downtime."},{term:"Feature Flags",definition:"Techniques that allow toggling features on/off without deploying new code, enabling gradual rollouts and A/B testing."},{term:"Jenkinsfile",definition:"A text file that defines a Jenkins Pipeline, using Groovy-based DSL for pipeline-as-code."},{term:"Pipeline as Code",definition:"Practice of defining build/deploy pipelines in version-controlled files rather than through UI configuration."},{term:"Build Stage",definition:"A phase in the pipeline that compiles code, runs linters, and creates artifacts from source code."},{term:"Test Stage",definition:"A phase that runs automated tests including unit tests, integration tests, and end-to-end tests."},{term:"Deploy Stage",definition:"A phase that pushes artifacts to target environments like staging, QA, or production."},{term:"Workflow",definition:"A configurable automated process in GitHub Actions defined in YAML files specifying jobs and steps."},{term:"Job",definition:"A set of steps in a workflow that execute on the same runner, with jobs running in parallel by default."},{term:"Step",definition:"An individual task in a job that can run commands or actions for specific operations."},{term:"Runner",definition:"A server that runs GitHub Actions workflows. Can be GitHub-hosted or self-hosted."},{term:"Action",definition:"A reusable unit of code for GitHub Actions that performs a specific task in a workflow."},{term:"CircleCI",definition:"A cloud-based CI/CD platform that automates build, test, and deploy processes with config.yml."},{term:"Travis CI",definition:"A hosted CI service that integrates with GitHub for automated testing and deployment."},{term:"Azure DevOps Pipelines",definition:"CI/CD service from Microsoft that supports any language, platform, and cloud deployment."},{term:"AWS CodePipeline",definition:"A fully managed CI/CD service for automating release pipelines on AWS infrastructure."},{term:"ArgoCD",definition:"A declarative GitOps continuous delivery tool for Kubernetes applications."},{term:"GitOps",definition:"A paradigm where Git is the single source of truth for infrastructure and application configuration."},{term:"Flux",definition:"A GitOps toolkit for keeping Kubernetes clusters in sync with sources of configuration."},{term:"Spinnaker",definition:"An open-source multi-cloud continuous delivery platform for releasing software changes."},{term:"Tekton",definition:"A Kubernetes-native framework for creating CI/CD pipelines as custom resources."},{term:"Build Cache",definition:"Mechanism to store and reuse previously computed build outputs to speed up subsequent builds."},{term:"Parallel Execution",definition:"Running multiple jobs or stages simultaneously to reduce overall pipeline duration."},{term:"Matrix Build",definition:"Running tests across multiple configurations (OS, language versions) in parallel."},{term:"Secrets Management",definition:"Securely storing and accessing sensitive data like API keys and passwords in CI/CD pipelines."},{term:"Environment Variables",definition:"Key-value pairs that configure pipeline behavior and pass configuration to build/deploy scripts."},{term:"Trigger",definition:"An event that starts a pipeline, such as push, pull request, schedule, or manual trigger."},{term:"Webhook",definition:"HTTP callbacks that notify CI/CD systems about repository events to trigger pipelines."},{term:"Approval Gates",definition:"Manual or automated checkpoints requiring approval before proceeding to next deployment stage."},{term:"Rollback",definition:"Reverting to a previous version of an application when issues are detected in a deployment."},{term:"Smoke Tests",definition:"Preliminary tests to verify that basic functionality works after deployment."},{term:"Integration Tests",definition:"Tests that verify different modules or services work together correctly."},{term:"End-to-End Tests",definition:"Tests that validate entire application flows from user perspective."},{term:"Code Coverage",definition:"A metric measuring the percentage of code executed during tests."},{term:"Static Analysis",definition:"Analyzing code without executing it to find bugs, security issues, and code smells."},{term:"Linting",definition:"Automated checking of source code for programmatic and stylistic errors."},{term:"Quality Gates",definition:"Criteria that code must meet before proceeding, like coverage thresholds or zero critical bugs."},{term:"Deployment Slot",definition:"Staging environment in Azure App Service for testing before swapping to production."},{term:"Infrastructure as Code",definition:"Managing infrastructure through configuration files that can be version-controlled and tested."},{term:"Immutable Infrastructure",definition:"Infrastructure that is never modified after deployment; changes require new deployments."}],commands:[{command:"gh workflow run workflow.yml",description:"Manually trigger GitHub Actions workflow"},{command:"gh run list",description:"List recent workflow runs"},{command:"gh run view --log",description:"View workflow run logs"},{command:"jenkins-cli build job-name",description:"Trigger Jenkins job from CLI"},{command:"gitlab-runner register",description:"Register a new GitLab runner"},{command:"gitlab-ci-lint .gitlab-ci.yml",description:"Validate GitLab CI config"},{command:"circleci local execute",description:"Run CircleCI jobs locally"},{command:"argocd app sync app-name",description:"Sync ArgoCD application"},{command:"argocd app list",description:"List ArgoCD applications"},{command:"flux reconcile kustomization",description:"Trigger Flux reconciliation"},{command:"tekton pipeline start pipeline",description:"Start Tekton pipeline"},{command:"tkn pipelinerun list",description:"List Tekton pipeline runs"},{command:"aws codepipeline start-pipeline-execution",description:"Start AWS CodePipeline"},{command:"az pipelines run --name pipeline",description:"Run Azure DevOps pipeline"},{command:"spinnaker pipeline execute",description:"Execute Spinnaker pipeline"},{command:"newman run collection.json",description:"Run Postman collection for API tests"},{command:"npm test",description:"Run npm test scripts"},{command:"pytest --cov=app tests/",description:"Run Python tests with coverage"},{command:"mvn clean install",description:"Build Maven project"},{command:"gradle build",description:"Build Gradle project"},{command:"make test",description:"Run Makefile test target"},{command:"sonar-scanner",description:"Run SonarQube analysis"},{command:"eslint --fix .",description:"Run ESLint with auto-fix"},{command:"black --check .",description:"Check Python formatting"},{command:"hadolint Dockerfile",description:"Lint Dockerfile"}],quiz:[{question:"What is the main goal of Continuous Integration?",options:["Deploy to production","Frequently merge and test code changes","Monitor applications","Manage infrastructure"],correct:1},{question:"What distinguishes Continuous Deployment from Continuous Delivery?",options:["More testing","Automatic deployment without manual approval","Better monitoring","Faster builds"],correct:1},{question:"What is a CI/CD pipeline?",options:["A type of container","Automated processes for build, test, and deploy","A monitoring tool","A version control system"],correct:1},{question:"Which deployment strategy uses two identical environments?",options:["Canary","Rolling","Blue-Green","A/B Testing"],correct:2},{question:"What is a build artifact?",options:["Source code","Test results","Output of the build process","Configuration file"],correct:2},{question:"What is a Jenkinsfile?",options:["Jenkins configuration","Pipeline definition file","Log file","Credential file"],correct:1},{question:"What is GitOps?",options:["Git operations","Git as single source of truth for config","GitHub operations","Git optimization"],correct:1},{question:"What is a canary deployment?",options:["Full release","Gradual rollout to subset of users","Emergency release","Blue-green switch"],correct:1},{question:"What is ArgoCD primarily used for?",options:["Container building","GitOps CD for Kubernetes","Monitoring","Testing"],correct:1},{question:"What triggers a pipeline?",options:["Manual only","Events like push, PR, schedule","Only on Fridays","Random"],correct:1},{question:"What is a runner in GitHub Actions?",options:["Fast pipeline","Server that executes workflows","Type of action","Workflow step"],correct:1},{question:"What is rolling deployment?",options:["Rollback","Incremental updates replacing old versions","Fast deployment","Manual deployment"],correct:1},{question:"What are feature flags used for?",options:["Flagging errors","Toggling features without deploying","Marking files","Security alerts"],correct:1},{question:"What is pipeline as code?",options:["Coding pipelines","Defining pipelines in version-controlled files","Pipeline encryption","Code testing"],correct:1},{question:"What does code coverage measure?",options:["Code quality","Percentage of code executed by tests","Code size","Code complexity"],correct:1},{question:"What is static analysis?",options:["Running tests","Analyzing code without executing it","Performance testing","Load testing"],correct:1},{question:"What is a quality gate?",options:["Code review","Criteria code must meet before proceeding","Deployment gate","Security check"],correct:1},{question:"What is a rollback?",options:["Moving forward","Reverting to previous version","Restarting pipeline","Deploying backup"],correct:1},{question:"What is Tekton?",options:["CI tool","Kubernetes-native CI/CD framework","Container tool","Monitoring tool"],correct:1},{question:"What are smoke tests?",options:["Performance tests","Preliminary tests for basic functionality","Security tests","Load tests"],correct:1},{question:"What is immutable infrastructure?",options:["Infrastructure that changes","Infrastructure never modified after deployment","Static infrastructure","Old infrastructure"],correct:1},{question:"What is a webhook?",options:["Web application","HTTP callback for event notification","Security hook","API endpoint"],correct:1},{question:"What is matrix build?",options:["Mathematical build","Running tests across multiple configurations","Single build","Complex build"],correct:1},{question:"What are approval gates?",options:["Security gates","Checkpoints requiring approval before deployment","Code gates","Test gates"],correct:1},{question:"What is linting?",options:["Code cleaning","Automated checking for code errors","Code compression","Code encryption"],correct:1}],codebase:[{title:"GitHub Actions Workflow",filename:".github/workflows/ci-cd.yml",language:"yaml",description:"Complete CI/CD pipeline with build, test, and deploy stages",code:"name: CI/CD Pipeline\n\non:\n  push:\n    branches: [main, develop]\n  pull_request:\n    branches: [main]\n\nenv:\n  REGISTRY: ghcr.io\n  IMAGE_NAME: ${{ github.repository }}\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      \n      - name: Setup Node.js\n        uses: actions/setup-node@v4\n        with:\n          node-version: '20'\n          cache: 'npm'\n      \n      - name: Install dependencies\n        run: npm ci\n      \n      - name: Run linting\n        run: npm run lint\n      \n      - name: Run tests\n        run: npm test -- --coverage\n      \n      - name: Upload coverage\n        uses: codecov/codecov-action@v3\n\n  build:\n    needs: test\n    runs-on: ubuntu-latest\n    permissions:\n      contents: read\n      packages: write\n    steps:\n      - uses: actions/checkout@v4\n      \n      - name: Log in to Container Registry\n        uses: docker/login-action@v3\n        with:\n          registry: ${{ env.REGISTRY }}\n          username: ${{ github.actor }}\n          password: ${{ secrets.GITHUB_TOKEN }}\n      \n      - name: Build and push Docker image\n        uses: docker/build-push-action@v5\n        with:\n          context: .\n          push: true\n          tags: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ github.sha }}\n\n  deploy:\n    needs: build\n    runs-on: ubuntu-latest\n    if: github.ref == 'refs/heads/main'\n    steps:\n      - name: Deploy to Kubernetes\n        uses: azure/k8s-deploy@v4\n        with:\n          manifests: k8s/\n          images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ github.sha }}"},{title:"GitLab CI Pipeline",filename:".gitlab-ci.yml",language:"yaml",description:"GitLab CI/CD pipeline with stages and environments",code:"stages:\n  - test\n  - build\n  - deploy\n\nvariables:\n  DOCKER_IMAGE: $CI_REGISTRY_IMAGE:$CI_COMMIT_SHA\n\ntest:\n  stage: test\n  image: node:20-alpine\n  cache:\n    paths:\n      - node_modules/\n  script:\n    - npm ci\n    - npm run lint\n    - npm test\n  coverage: '/Lines\\s*:\\s*(\\d+\\.?\\d*)%/'\n  artifacts:\n    reports:\n      coverage_report:\n        coverage_format: cobertura\n        path: coverage/cobertura-coverage.xml\n\nbuild:\n  stage: build\n  image: docker:24\n  services:\n    - docker:24-dind\n  before_script:\n    - docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $CI_REGISTRY\n  script:\n    - docker build -t $DOCKER_IMAGE .\n    - docker push $DOCKER_IMAGE\n  only:\n    - main\n    - develop\n\ndeploy_staging:\n  stage: deploy\n  image: bitnami/kubectl:latest\n  script:\n    - kubectl set image deployment/myapp myapp=$DOCKER_IMAGE\n  environment:\n    name: staging\n    url: https://staging.example.com\n  only:\n    - develop\n\ndeploy_production:\n  stage: deploy\n  image: bitnami/kubectl:latest\n  script:\n    - kubectl set image deployment/myapp myapp=$DOCKER_IMAGE\n  environment:\n    name: production\n    url: https://example.com\n  when: manual\n  only:\n    - main"},{title:"Jenkinsfile",filename:"Jenkinsfile",language:"groovy",description:"Declarative Jenkins pipeline with parallel stages",code:"pipeline {\n    agent any\n    \n    environment {\n        DOCKER_REGISTRY = 'registry.example.com'\n        IMAGE_NAME = 'myapp'\n    }\n    \n    stages {\n        stage('Checkout') {\n            steps {\n                checkout scm\n            }\n        }\n        \n        stage('Test') {\n            parallel {\n                stage('Unit Tests') {\n                    steps {\n                        sh 'npm ci'\n                        sh 'npm run test:unit'\n                    }\n                }\n                stage('Integration Tests') {\n                    steps {\n                        sh 'npm run test:integration'\n                    }\n                }\n                stage('Lint') {\n                    steps {\n                        sh 'npm run lint'\n                    }\n                }\n            }\n        }\n        \n        stage('Build') {\n            steps {\n                script {\n                    docker.build(\"${DOCKER_REGISTRY}/${IMAGE_NAME}:${BUILD_NUMBER}\")\n                }\n            }\n        }\n        \n        stage('Push') {\n            steps {\n                script {\n                    docker.withRegistry(\"https://${DOCKER_REGISTRY}\", 'docker-credentials') {\n                        docker.image(\"${DOCKER_REGISTRY}/${IMAGE_NAME}:${BUILD_NUMBER}\").push()\n                        docker.image(\"${DOCKER_REGISTRY}/${IMAGE_NAME}:${BUILD_NUMBER}\").push('latest')\n                    }\n                }\n            }\n        }\n        \n        stage('Deploy to Staging') {\n            steps {\n                sh \"kubectl set image deployment/myapp myapp=${DOCKER_REGISTRY}/${IMAGE_NAME}:${BUILD_NUMBER}\"\n            }\n        }\n        \n        stage('Deploy to Production') {\n            when {\n                branch 'main'\n            }\n            input {\n                message 'Deploy to production?'\n                ok 'Deploy'\n            }\n            steps {\n                sh \"kubectl set image deployment/myapp myapp=${DOCKER_REGISTRY}/${IMAGE_NAME}:${BUILD_NUMBER} --context=production\"\n            }\n        }\n    }\n    \n    post {\n        always {\n            cleanWs()\n        }\n        failure {\n            slackSend channel: '#alerts', message: \"Build failed: ${env.JOB_NAME} #${env.BUILD_NUMBER}\"\n        }\n    }\n}"},{title:"ArgoCD Application",filename:"argocd-app.yaml",language:"yaml",description:"GitOps deployment with ArgoCD",code:"apiVersion: argoproj.io/v1alpha1\nkind: Application\nmetadata:\n  name: myapp\n  namespace: argocd\nspec:\n  project: default\n  source:\n    repoURL: https://github.com/myorg/myapp.git\n    targetRevision: HEAD\n    path: k8s/overlays/production\n  destination:\n    server: https://kubernetes.default.svc\n    namespace: myapp\n  syncPolicy:\n    automated:\n      prune: true\n      selfHeal: true\n    syncOptions:\n      - CreateNamespace=true\n    retry:\n      limit: 5\n      backoff:\n        duration: 5s\n        factor: 2\n        maxDuration: 3m"}]},{id:"aws",name:"AWS",icon:"‚òÅÔ∏è",color:"#ff9900",flashcards:[{term:"EC2",definition:"Elastic Compute Cloud - A web service providing resizable compute capacity in the cloud as virtual servers (instances)."},{term:"S3",definition:"Simple Storage Service - Object storage service offering scalability, data availability, security, and performance for any amount of data."},{term:"Lambda",definition:"A serverless compute service that runs code in response to events without provisioning or managing servers."},{term:"VPC",definition:"Virtual Private Cloud - A logically isolated section of AWS where you can launch resources in a virtual network you define."},{term:"IAM",definition:"Identity and Access Management - A service for securely controlling access to AWS services and resources."},{term:"EKS",definition:"Elastic Kubernetes Service - A managed Kubernetes service to run Kubernetes on AWS without installing and operating your own cluster."},{term:"RDS",definition:"Relational Database Service - A managed database service supporting multiple database engines like MySQL, PostgreSQL, and Aurora."},{term:"CloudFormation",definition:"Infrastructure as Code service that lets you model and provision AWS resources using templates."},{term:"Route 53",definition:"A scalable Domain Name System (DNS) web service for routing end users to applications and managing domain registrations."},{term:"ELB",definition:"Elastic Load Balancing - Automatically distributes incoming application traffic across multiple targets like EC2 instances."},{term:"CloudWatch",definition:"A monitoring and observability service for AWS resources and applications, providing metrics, logs, and alarms."},{term:"ECR",definition:"Elastic Container Registry - A fully managed Docker container registry for storing, managing, and deploying container images."}],quiz:[{question:"What type of service is AWS Lambda?",options:["Database","Serverless compute","Storage","Networking"],correct:1},{question:"What does S3 stand for?",options:["Simple Server Service","Simple Storage Service","Secure Storage System","Server Storage Service"],correct:1},{question:"Which service is used for managing access to AWS resources?",options:["VPC","IAM","EC2","S3"],correct:1},{question:"What is AWS EKS?",options:["A database service","A managed Kubernetes service","A storage service","A monitoring tool"],correct:1},{question:"Which service provides Infrastructure as Code on AWS?",options:["Lambda","EC2","CloudFormation","RDS"],correct:2},{question:"What is Route 53 used for?",options:["Load balancing","Container orchestration","DNS and domain routing","Serverless functions"],correct:2}],codebase:[{title:"Lambda Function with API Gateway",filename:"lambda-api.py",language:"python",description:"AWS Lambda handler with API Gateway integration",code:"import json\nimport boto3\nfrom datetime import datetime\n\ndynamodb = boto3.resource('dynamodb')\ntable = dynamodb.Table('Items')\n\ndef lambda_handler(event, context):\n    \"\"\"\n    Lambda function handler for API Gateway\n    \"\"\"\n    http_method = event.get('httpMethod', 'GET')\n    path = event.get('path', '/')\n    \n    try:\n        if http_method == 'GET':\n            response = table.scan()\n            return {\n                'statusCode': 200,\n                'headers': {'Content-Type': 'application/json'},\n                'body': json.dumps(response['Items'])\n            }\n        \n        elif http_method == 'POST':\n            body = json.loads(event.get('body', '{}'))\n            item = {\n                'id': str(datetime.now().timestamp()),\n                'name': body.get('name'),\n                'created_at': datetime.now().isoformat()\n            }\n            table.put_item(Item=item)\n            return {\n                'statusCode': 201,\n                'headers': {'Content-Type': 'application/json'},\n                'body': json.dumps(item)\n            }\n        \n        else:\n            return {\n                'statusCode': 405,\n                'body': json.dumps({'error': 'Method not allowed'})\n            }\n    \n    except Exception as e:\n        return {\n            'statusCode': 500,\n            'body': json.dumps({'error': str(e)})\n        }"},{title:"CloudFormation Template",filename:"infrastructure.yaml",language:"yaml",description:"CloudFormation template for VPC with public/private subnets",code:"AWSTemplateFormatVersion: '2010-09-09'\nDescription: VPC with public and private subnets\n\nParameters:\n  Environment:\n    Type: String\n    Default: production\n    AllowedValues: [development, staging, production]\n\nResources:\n  VPC:\n    Type: AWS::EC2::VPC\n    Properties:\n      CidrBlock: 10.0.0.0/16\n      EnableDnsHostnames: true\n      EnableDnsSupport: true\n      Tags:\n        - Key: Name\n          Value: !Sub ${Environment}-vpc\n\n  PublicSubnet1:\n    Type: AWS::EC2::Subnet\n    Properties:\n      VpcId: !Ref VPC\n      CidrBlock: 10.0.1.0/24\n      AvailabilityZone: !Select [0, !GetAZs '']\n      MapPublicIpOnLaunch: true\n      Tags:\n        - Key: Name\n          Value: !Sub ${Environment}-public-1\n\n  PrivateSubnet1:\n    Type: AWS::EC2::Subnet\n    Properties:\n      VpcId: !Ref VPC\n      CidrBlock: 10.0.10.0/24\n      AvailabilityZone: !Select [0, !GetAZs '']\n      Tags:\n        - Key: Name\n          Value: !Sub ${Environment}-private-1\n\n  InternetGateway:\n    Type: AWS::EC2::InternetGateway\n\n  AttachGateway:\n    Type: AWS::EC2::VPCGatewayAttachment\n    Properties:\n      VpcId: !Ref VPC\n      InternetGatewayId: !Ref InternetGateway\n\nOutputs:\n  VPCId:\n    Value: !Ref VPC\n    Export:\n      Name: !Sub ${Environment}-VPCId"},{title:"IAM Policy Document",filename:"iam-policy.json",language:"json",description:"Least-privilege IAM policy for S3 and DynamoDB access",code:'{\n  "Version": "2012-10-17",\n  "Statement": [\n    {\n      "Sid": "S3Access",\n      "Effect": "Allow",\n      "Action": [\n        "s3:GetObject",\n        "s3:PutObject",\n        "s3:DeleteObject"\n      ],\n      "Resource": "arn:aws:s3:::my-bucket/*"\n    },\n    {\n      "Sid": "DynamoDBAccess",\n      "Effect": "Allow",\n      "Action": [\n        "dynamodb:GetItem",\n        "dynamodb:PutItem",\n        "dynamodb:UpdateItem",\n        "dynamodb:DeleteItem",\n        "dynamodb:Query",\n        "dynamodb:Scan"\n      ],\n      "Resource": [\n        "arn:aws:dynamodb:us-east-1:123456789012:table/MyTable",\n        "arn:aws:dynamodb:us-east-1:123456789012:table/MyTable/index/*"\n      ]\n    },\n    {\n      "Sid": "CloudWatchLogs",\n      "Effect": "Allow",\n      "Action": [\n        "logs:CreateLogGroup",\n        "logs:CreateLogStream",\n        "logs:PutLogEvents"\n      ],\n      "Resource": "arn:aws:logs:*:*:*"\n    }\n  ]\n}'},{title:"AWS CLI Deployment Script",filename:"deploy-aws.sh",language:"bash",description:"Deployment script using AWS CLI for ECS",code:'#!/bin/bash\nset -e\n\n# Configuration\nCLUSTER_NAME="production-cluster"\nSERVICE_NAME="myapp-service"\nTASK_FAMILY="myapp"\nECR_REPO="123456789012.dkr.ecr.us-east-1.amazonaws.com/myapp"\nIMAGE_TAG=${1:-latest}\n\n# Login to ECR\naws ecr get-login-password --region us-east-1 | \\\n  docker login --username AWS --password-stdin $ECR_REPO\n\n# Build and push image\ndocker build -t $ECR_REPO:$IMAGE_TAG .\ndocker push $ECR_REPO:$IMAGE_TAG\n\n# Get current task definition\nTASK_DEF=$(aws ecs describe-task-definition --task-definition $TASK_FAMILY)\n\n# Create new task definition with updated image\nNEW_TASK_DEF=$(echo $TASK_DEF | jq --arg IMAGE "$ECR_REPO:$IMAGE_TAG" \\\n  \'.taskDefinition | .containerDefinitions[0].image = $IMAGE | \n   del(.taskDefinitionArn, .revision, .status, .requiresAttributes, .compatibilities, .registeredAt, .registeredBy)\')\n\n# Register new task definition\nNEW_TASK_ARN=$(aws ecs register-task-definition --cli-input-json "$NEW_TASK_DEF" \\\n  --query \'taskDefinition.taskDefinitionArn\' --output text)\n\n# Update service\naws ecs update-service \\\n  --cluster $CLUSTER_NAME \\\n  --service $SERVICE_NAME \\\n  --task-definition $NEW_TASK_ARN\n\necho "Deployed $ECR_REPO:$IMAGE_TAG to $SERVICE_NAME"'}]},{id:"terraform",name:"Terraform",icon:"üèóÔ∏è",color:"#7b42bc",flashcards:[{term:"Infrastructure as Code",definition:"Managing and provisioning infrastructure through machine-readable configuration files rather than manual processes."},{term:"Provider",definition:"A plugin that allows Terraform to interact with cloud platforms, SaaS providers, and other APIs like AWS, Azure, or GCP."},{term:"Resource",definition:"The most important element in Terraform - describes infrastructure objects like compute instances, databases, or networks."},{term:"State File",definition:"A JSON file that Terraform uses to map real-world resources to your configuration and track metadata."},{term:"Module",definition:"A container for multiple resources used together, enabling reusable and shareable infrastructure configurations."},{term:"Terraform Plan",definition:"A command that creates an execution plan showing what actions Terraform will take to achieve the desired state."},{term:"Terraform Apply",definition:"A command that executes the actions proposed in a Terraform plan to create, update, or delete infrastructure."},{term:"Variable",definition:"Input parameters that make Terraform configurations flexible and reusable, defined using variable blocks."},{term:"Output",definition:"Values exported from a Terraform module, useful for passing data between modules or displaying to users."},{term:"Backend",definition:"Determines how state is stored and how operations are executed. Remote backends enable team collaboration."}],quiz:[{question:"What is Infrastructure as Code (IaC)?",options:["Manual server configuration","Managing infrastructure through code/configuration files","A type of database","Container orchestration"],correct:1},{question:"What does a Terraform provider do?",options:["Stores state","Interacts with cloud platforms and APIs","Runs containers","Manages secrets"],correct:1},{question:"What is stored in the Terraform state file?",options:["Source code","Mapping of resources to configuration","Container images","User credentials"],correct:1},{question:'What does "terraform plan" do?',options:["Applies changes","Shows proposed changes","Destroys resources","Initializes modules"],correct:1},{question:"What is a Terraform module?",options:["A single resource","A container for reusable resources","A variable","A provider"],correct:1}],codebase:[{title:"AWS VPC Module",filename:"main.tf",language:"hcl",description:"Complete Terraform configuration for AWS VPC with modules",code:'terraform {\n  required_version = ">= 1.0"\n  required_providers {\n    aws = {\n      source  = "hashicorp/aws"\n      version = "~> 5.0"\n    }\n  }\n  backend "s3" {\n    bucket         = "my-terraform-state"\n    key            = "prod/terraform.tfstate"\n    region         = "us-east-1"\n    dynamodb_table = "terraform-locks"\n    encrypt        = true\n  }\n}\n\nprovider "aws" {\n  region = var.aws_region\n  default_tags {\n    tags = {\n      Environment = var.environment\n      ManagedBy   = "terraform"\n    }\n  }\n}\n\nmodule "vpc" {\n  source  = "terraform-aws-modules/vpc/aws"\n  version = "5.0.0"\n\n  name = "${var.project}-vpc"\n  cidr = "10.0.0.0/16"\n\n  azs             = ["us-east-1a", "us-east-1b", "us-east-1c"]\n  private_subnets = ["10.0.1.0/24", "10.0.2.0/24", "10.0.3.0/24"]\n  public_subnets  = ["10.0.101.0/24", "10.0.102.0/24", "10.0.103.0/24"]\n\n  enable_nat_gateway = true\n  single_nat_gateway = var.environment != "production"\n\n  tags = {\n    Project = var.project\n  }\n}\n\nmodule "eks" {\n  source  = "terraform-aws-modules/eks/aws"\n  version = "19.0.0"\n\n  cluster_name    = "${var.project}-cluster"\n  cluster_version = "1.28"\n\n  vpc_id     = module.vpc.vpc_id\n  subnet_ids = module.vpc.private_subnets\n\n  eks_managed_node_groups = {\n    default = {\n      min_size     = 2\n      max_size     = 10\n      desired_size = 3\n      instance_types = ["t3.medium"]\n    }\n  }\n}'},{title:"Variables & Outputs",filename:"variables.tf",language:"hcl",description:"Terraform variables with validation and outputs",code:'# variables.tf\nvariable "aws_region" {\n  description = "AWS region for resources"\n  type        = string\n  default     = "us-east-1"\n}\n\nvariable "environment" {\n  description = "Environment name"\n  type        = string\n  validation {\n    condition     = contains(["development", "staging", "production"], var.environment)\n    error_message = "Environment must be development, staging, or production."\n  }\n}\n\nvariable "project" {\n  description = "Project name"\n  type        = string\n}\n\nvariable "instance_config" {\n  description = "EC2 instance configuration"\n  type = object({\n    instance_type = string\n    volume_size   = number\n    volume_type   = string\n  })\n  default = {\n    instance_type = "t3.micro"\n    volume_size   = 20\n    volume_type   = "gp3"\n  }\n}\n\n# outputs.tf\noutput "vpc_id" {\n  description = "VPC ID"\n  value       = module.vpc.vpc_id\n}\n\noutput "cluster_endpoint" {\n  description = "EKS cluster endpoint"\n  value       = module.eks.cluster_endpoint\n  sensitive   = true\n}\n\noutput "private_subnets" {\n  description = "Private subnet IDs"\n  value       = module.vpc.private_subnets\n}'},{title:"Terraform Module",filename:"modules/app/main.tf",language:"hcl",description:"Reusable Terraform module for application deployment",code:'# modules/app/main.tf\nresource "aws_security_group" "app" {\n  name_prefix = "${var.name}-sg"\n  vpc_id      = var.vpc_id\n\n  ingress {\n    from_port       = var.app_port\n    to_port         = var.app_port\n    protocol        = "tcp"\n    security_groups = [var.alb_security_group_id]\n  }\n\n  egress {\n    from_port   = 0\n    to_port     = 0\n    protocol    = "-1"\n    cidr_blocks = ["0.0.0.0/0"]\n  }\n\n  lifecycle {\n    create_before_destroy = true\n  }\n}\n\nresource "aws_ecs_task_definition" "app" {\n  family                   = var.name\n  network_mode             = "awsvpc"\n  requires_compatibilities = ["FARGATE"]\n  cpu                      = var.cpu\n  memory                   = var.memory\n  execution_role_arn       = aws_iam_role.execution.arn\n  task_role_arn            = aws_iam_role.task.arn\n\n  container_definitions = jsonencode([{\n    name  = var.name\n    image = var.image\n    portMappings = [{\n      containerPort = var.app_port\n      protocol      = "tcp"\n    }]\n    environment = var.environment_variables\n    secrets     = var.secrets\n    logConfiguration = {\n      logDriver = "awslogs"\n      options = {\n        awslogs-group         = aws_cloudwatch_log_group.app.name\n        awslogs-region        = data.aws_region.current.name\n        awslogs-stream-prefix = var.name\n      }\n    }\n  }])\n}\n\nresource "aws_ecs_service" "app" {\n  name            = var.name\n  cluster         = var.cluster_id\n  task_definition = aws_ecs_task_definition.app.arn\n  desired_count   = var.desired_count\n  launch_type     = "FARGATE"\n\n  network_configuration {\n    subnets          = var.subnet_ids\n    security_groups  = [aws_security_group.app.id]\n    assign_public_ip = false\n  }\n\n  load_balancer {\n    target_group_arn = var.target_group_arn\n    container_name   = var.name\n    container_port   = var.app_port\n  }\n}'}]},{id:"git",name:"Git",icon:"üìÅ",color:"#f05032",flashcards:[{term:"Repository",definition:"A directory containing your project files and the entire history of changes tracked by Git."},{term:"Commit",definition:"A snapshot of changes saved to the repository history with a unique SHA identifier and commit message."},{term:"Branch",definition:"An independent line of development allowing you to work on features or fixes without affecting the main codebase."},{term:"Merge",definition:"The process of combining changes from different branches into a single branch, integrating separate development efforts."},{term:"Pull Request",definition:"A method for submitting contributions where changes are reviewed before being merged into the target branch."},{term:"Rebase",definition:"An alternative to merging that applies commits from one branch on top of another, creating a linear history."},{term:"Git Clone",definition:"Creates a local copy of a remote repository, including all files, branches, and commit history."},{term:"Git Stash",definition:"Temporarily saves changes that are not ready to be committed, allowing you to switch branches cleanly."}],quiz:[{question:"What is a Git commit?",options:["A branch","A snapshot of changes","A merge conflict","A remote repository"],correct:1},{question:"What is the purpose of a branch in Git?",options:["Delete history","Independent line of development","Store backups","Connect to remote"],correct:1},{question:"What does git rebase do?",options:["Deletes commits","Applies commits on top of another branch","Creates a backup","Merges conflicts"],correct:1},{question:"What is a Pull Request?",options:["Downloading code","A method for reviewing and merging changes","A type of branch","A commit message"],correct:1}],codebase:[{title:"Git Workflow Script",filename:"git-workflow.sh",language:"bash",description:"Common Git workflow operations and best practices",code:'#!/bin/bash\n# Git Workflow Script\n\n# Feature branch workflow\ncreate_feature() {\n    git checkout main\n    git pull origin main\n    git checkout -b feature/$1\n    echo "Created feature branch: feature/$1"\n}\n\n# Sync with main\nsync_main() {\n    git fetch origin\n    git rebase origin/main\n    echo "Synced with main branch"\n}\n\n# Commit with conventional commit format\ncommit() {\n    local type=$1\n    local message=$2\n    git add -A\n    git commit -m "$type: $message"\n}\n\n# Interactive rebase to clean up commits\ncleanup_commits() {\n    local count=${1:-5}\n    git rebase -i HEAD~$count\n}\n\n# Push and create PR\npush_and_pr() {\n    local branch=$(git branch --show-current)\n    git push -u origin $branch\n    gh pr create --fill\n}\n\n# Stash with message\nsave_work() {\n    git stash push -m "$1"\n}\n\n# Usage examples:\n# create_feature "add-login"\n# commit "feat" "add user authentication"\n# commit "fix" "resolve login bug"\n# sync_main\n# push_and_pr'},{title:".gitconfig",filename:".gitconfig",language:"ini",description:"Git configuration with useful aliases and settings",code:"[user]\n    name = Your Name\n    email = your.email@example.com\n\n[core]\n    editor = vim\n    autocrlf = input\n    excludesfile = ~/.gitignore_global\n\n[init]\n    defaultBranch = main\n\n[pull]\n    rebase = true\n\n[fetch]\n    prune = true\n\n[alias]\n    st = status -sb\n    co = checkout\n    br = branch\n    ci = commit\n    lg = log --oneline --graph --decorate -20\n    ll = log --pretty=format:'%C(yellow)%h%Creset %s %C(blue)<%an>%Creset %C(green)(%cr)%Creset' -20\n    unstage = reset HEAD --\n    last = log -1 HEAD --stat\n    amend = commit --amend --no-edit\n    undo = reset --soft HEAD^\n    stash-all = stash save --include-untracked\n    aliases = config --get-regexp alias\n    branches = branch -a\n    remotes = remote -v\n    contributors = shortlog -sn\n    today = log --since=midnight --author='Your Name' --oneline\n\n[color]\n    ui = auto\n\n[merge]\n    conflictstyle = diff3\n    tool = vscode\n\n[diff]\n    colorMoved = zebra\n\n[credential]\n    helper = cache --timeout=3600"},{title:"Pre-commit Hooks",filename:".pre-commit-config.yaml",language:"yaml",description:"Pre-commit hooks for code quality",code:"repos:\n  - repo: https://github.com/pre-commit/pre-commit-hooks\n    rev: v4.5.0\n    hooks:\n      - id: trailing-whitespace\n      - id: end-of-file-fixer\n      - id: check-yaml\n      - id: check-json\n      - id: check-added-large-files\n        args: ['--maxkb=1000']\n      - id: detect-private-key\n      - id: check-merge-conflict\n\n  - repo: https://github.com/psf/black\n    rev: 24.1.0\n    hooks:\n      - id: black\n\n  - repo: https://github.com/pycqa/flake8\n    rev: 7.0.0\n    hooks:\n      - id: flake8\n        args: ['--max-line-length=100']\n\n  - repo: https://github.com/pre-commit/mirrors-eslint\n    rev: v8.56.0\n    hooks:\n      - id: eslint\n        files: \\.[jt]sx?$\n        types: [file]\n        additional_dependencies:\n          - eslint@8.56.0\n          - eslint-config-prettier@9.1.0\n\n  - repo: https://github.com/hadolint/hadolint\n    rev: v2.12.0\n    hooks:\n      - id: hadolint-docker"}]},{id:"linux",name:"Linux",icon:"üêß",color:"#fcc624",flashcards:[{term:"Shell",definition:"A command-line interface that interprets user commands and communicates with the operating system kernel."},{term:"Bash",definition:"Bourne Again SHell - The most common shell on Linux systems, used for command-line operations and scripting."},{term:"sudo",definition:"A command that allows users to run programs with the security privileges of another user, typically root."},{term:"chmod",definition:"A command to change file access permissions, controlling read, write, and execute rights for users."},{term:"grep",definition:"A command-line utility for searching plain-text data for lines matching a regular expression or pattern."},{term:"SSH",definition:"Secure Shell - A cryptographic network protocol for secure communication and remote server access."},{term:"systemd",definition:"A system and service manager for Linux, responsible for initializing and managing system services."},{term:"Package Manager",definition:"Tools like apt, yum, or dnf that automate installing, updating, configuring, and removing software packages."},{term:"Cron",definition:"A time-based job scheduler that runs commands or scripts automatically at specified times or intervals."},{term:"File Permissions",definition:"Linux uses read (r), write (w), and execute (x) permissions for owner, group, and others to control access."}],quiz:[{question:"What is the purpose of the sudo command?",options:["List files","Run commands as another user (typically root)","Search for text","Change directories"],correct:1},{question:"Which command is used to change file permissions?",options:["chown","chmod","chgrp","chperm"],correct:1},{question:"What does SSH stand for?",options:["Simple Shell Handler","Secure Shell","System Shell Host","Super Secure Handler"],correct:1},{question:"What is systemd used for?",options:["File editing","System and service management","Network configuration","User authentication"],correct:1},{question:"What does grep do?",options:["Manages packages","Searches for text patterns","Compresses files","Creates directories"],correct:1}],codebase:[{title:"Bash Script Template",filename:"script-template.sh",language:"bash",description:"Professional bash script template with error handling and logging",code:'#!/bin/bash\nset -euo pipefail\nIFS=$\'\\n\\t\'\n\n# Script configuration\nreadonly SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"\nreadonly SCRIPT_NAME="$(basename "${BASH_SOURCE[0]}")"\nreadonly LOG_FILE="/var/log/${SCRIPT_NAME%.sh}.log"\n\n# Colors for output\nreadonly RED=\'\\033[0;31m\'\nreadonly GREEN=\'\\033[0;32m\'\nreadonly YELLOW=\'\\033[1;33m\'\nreadonly NC=\'\\033[0m\'\n\n# Logging functions\nlog() { echo -e "$(date \'+%Y-%m-%d %H:%M:%S\') [INFO] $*" | tee -a "$LOG_FILE"; }\nwarn() { echo -e "$(date \'+%Y-%m-%d %H:%M:%S\') ${YELLOW}[WARN]${NC} $*" | tee -a "$LOG_FILE"; }\nerror() { echo -e "$(date \'+%Y-%m-%d %H:%M:%S\') ${RED}[ERROR]${NC} $*" | tee -a "$LOG_FILE" >&2; }\nsuccess() { echo -e "$(date \'+%Y-%m-%d %H:%M:%S\') ${GREEN}[OK]${NC} $*" | tee -a "$LOG_FILE"; }\n\n# Cleanup function\ncleanup() {\n    local exit_code=$?\n    log "Cleaning up..."\n    # Add cleanup tasks here\n    exit $exit_code\n}\ntrap cleanup EXIT\n\n# Check if running as root\ncheck_root() {\n    if [[ $EUID -ne 0 ]]; then\n        error "This script must be run as root"\n        exit 1\n    fi\n}\n\n# Usage function\nusage() {\n    cat << EOF\nUsage: $SCRIPT_NAME [OPTIONS]\n\nOptions:\n    -h, --help      Show this help message\n    -v, --verbose   Enable verbose output\n    -d, --dry-run   Dry run mode\n\nExamples:\n    $SCRIPT_NAME --verbose\n    $SCRIPT_NAME --dry-run\nEOF\n}\n\n# Parse arguments\nparse_args() {\n    while [[ $# -gt 0 ]]; do\n        case $1 in\n            -h|--help) usage; exit 0 ;;\n            -v|--verbose) VERBOSE=true ;;\n            -d|--dry-run) DRY_RUN=true ;;\n            *) error "Unknown option: $1"; usage; exit 1 ;;\n        esac\n        shift\n    done\n}\n\n# Main function\nmain() {\n    log "Starting $SCRIPT_NAME..."\n    parse_args "$@"\n    \n    # Your script logic here\n    \n    success "Script completed successfully"\n}\n\nmain "$@"'},{title:"Systemd Service Unit",filename:"myapp.service",language:"ini",description:"Systemd service unit file for application management",code:'[Unit]\nDescription=My Application Service\nDocumentation=https://docs.example.com\nAfter=network.target postgresql.service\nWants=postgresql.service\n\n[Service]\nType=simple\nUser=appuser\nGroup=appgroup\nWorkingDirectory=/opt/myapp\nEnvironment="NODE_ENV=production"\nEnvironment="PORT=3000"\nEnvironmentFile=-/etc/myapp/env\n\nExecStartPre=/usr/bin/npm run migrate\nExecStart=/usr/bin/node /opt/myapp/server.js\nExecReload=/bin/kill -HUP $MAINPID\nExecStop=/bin/kill -TERM $MAINPID\n\nRestart=always\nRestartSec=10\nTimeoutStartSec=30\nTimeoutStopSec=30\n\nStandardOutput=journal\nStandardError=journal\nSyslogIdentifier=myapp\n\n# Security hardening\nNoNewPrivileges=true\nPrivateTmp=true\nProtectSystem=strict\nProtectHome=true\nReadWritePaths=/opt/myapp/data /var/log/myapp\n\n[Install]\nWantedBy=multi-user.target'},{title:"Server Setup Script",filename:"server-setup.sh",language:"bash",description:"Initial server setup and hardening script",code:"#!/bin/bash\nset -euo pipefail\n\n# Update system\napt-get update && apt-get upgrade -y\n\n# Install essential packages\napt-get install -y \\\n    curl wget git vim htop \\\n    ufw fail2ban \\\n    unattended-upgrades \\\n    apt-transport-https ca-certificates\n\n# Create application user\nuseradd -m -s /bin/bash -G sudo appuser\n\n# Configure firewall\nufw default deny incoming\nufw default allow outgoing\nufw allow ssh\nufw allow 80/tcp\nufw allow 443/tcp\nufw --force enable\n\n# Configure fail2ban\ncat > /etc/fail2ban/jail.local << 'EOF'\n[DEFAULT]\nbantime = 3600\nfindtime = 600\nmaxretry = 5\n\n[sshd]\nenabled = true\nport = ssh\nfilter = sshd\nlogpath = /var/log/auth.log\nEOF\nsystemctl enable fail2ban\nsystemctl start fail2ban\n\n# SSH hardening\nsed -i 's/#PermitRootLogin yes/PermitRootLogin no/' /etc/ssh/sshd_config\nsed -i 's/#PasswordAuthentication yes/PasswordAuthentication no/' /etc/ssh/sshd_config\nsystemctl restart sshd\n\n# Enable automatic updates\ndpkg-reconfigure -plow unattended-upgrades\n\necho \"Server setup complete!\""}]},{id:"monitoring",name:"Monitoring",icon:"üìä",color:"#00c853",flashcards:[{term:"Prometheus",definition:"An open-source monitoring and alerting toolkit designed for reliability, using a pull-based model and time-series database."},{term:"Grafana",definition:"An open-source analytics and visualization platform for monitoring data, creating dashboards from various data sources."},{term:"Metrics",definition:"Numerical measurements collected over time like CPU usage, memory consumption, request latency, and error rates."},{term:"Logging",definition:"The practice of recording events and messages from applications and systems for debugging, auditing, and analysis."},{term:"Alerting",definition:"Automated notifications triggered when metrics exceed thresholds, enabling quick response to issues."},{term:"APM",definition:"Application Performance Monitoring - Tools that track application performance, errors, and user experience."},{term:"ELK Stack",definition:"Elasticsearch, Logstash, and Kibana - A popular stack for log aggregation, search, and visualization."},{term:"SLI/SLO/SLA",definition:"Service Level Indicator (metric), Objective (target), and Agreement (contract) - Key concepts for reliability measurement."}],commands:[{command:"prometheus --config.file=prometheus.yml",description:"Start Prometheus with config"},{command:"curl localhost:9090/metrics",description:"View Prometheus metrics endpoint"},{command:"grafana-server",description:"Start Grafana server"},{command:"journalctl -u service-name -f",description:"Follow systemd service logs"},{command:"tail -f /var/log/syslog",description:"Follow system logs"}],quiz:[{question:"What is Prometheus primarily used for?",options:["Log management","Monitoring and alerting","Container orchestration","Configuration management"],correct:1},{question:"What does Grafana help you create?",options:["Containers","Alerts","Visualization dashboards","Logs"],correct:2},{question:"What does ELK stand for?",options:["Elastic, Lambda, Kubernetes","Elasticsearch, Logstash, Kibana","Event, Log, Key","External Load Keeper"],correct:1},{question:"What is an SLO?",options:["Service Level Output","Service Level Objective","System Log Observer","Server Load Optimizer"],correct:1}],codebase:[{title:"Prometheus Configuration",filename:"prometheus.yml",language:"yaml",description:"Prometheus server configuration with scrape targets and alerting",code:"global:\n  scrape_interval: 15s\n  evaluation_interval: 15s\n\nalerting:\n  alertmanagers:\n    - static_configs:\n        - targets: ['alertmanager:9093']\n\nrule_files:\n  - '/etc/prometheus/rules/*.yml'\n\nscrape_configs:\n  - job_name: 'prometheus'\n    static_configs:\n      - targets: ['localhost:9090']\n\n  - job_name: 'node-exporter'\n    static_configs:\n      - targets: ['node-exporter:9100']\n\n  - job_name: 'kubernetes-pods'\n    kubernetes_sd_configs:\n      - role: pod\n    relabel_configs:\n      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]\n        action: keep\n        regex: true\n      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]\n        action: replace\n        target_label: __metrics_path__\n        regex: (.+)\n\n  - job_name: 'application'\n    metrics_path: '/metrics'\n    static_configs:\n      - targets: ['app:8080']\n        labels:\n          environment: 'production'\n          service: 'myapp'"},{title:"Alerting Rules",filename:"alerts.yml",language:"yaml",description:"Prometheus alerting rules for common scenarios",code:'groups:\n  - name: application\n    rules:\n      - alert: HighErrorRate\n        expr: rate(http_requests_total{status=~"5.."}[5m]) / rate(http_requests_total[5m]) > 0.05\n        for: 5m\n        labels:\n          severity: critical\n        annotations:\n          summary: "High error rate detected"\n          description: "Error rate is {{ $value | humanizePercentage }} for {{ $labels.instance }}"\n\n      - alert: HighLatency\n        expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) > 0.5\n        for: 10m\n        labels:\n          severity: warning\n        annotations:\n          summary: "High latency detected"\n          description: "P95 latency is {{ $value }}s"\n\n  - name: infrastructure\n    rules:\n      - alert: HighCPUUsage\n        expr: 100 - (avg by(instance) (rate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 80\n        for: 15m\n        labels:\n          severity: warning\n        annotations:\n          summary: "High CPU usage on {{ $labels.instance }}"\n\n      - alert: HighMemoryUsage\n        expr: (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100 > 85\n        for: 10m\n        labels:\n          severity: warning\n        annotations:\n          summary: "High memory usage on {{ $labels.instance }}"\n\n      - alert: DiskSpaceLow\n        expr: (node_filesystem_avail_bytes / node_filesystem_size_bytes) * 100 < 10\n        for: 5m\n        labels:\n          severity: critical\n        annotations:\n          summary: "Low disk space on {{ $labels.instance }}"'},{title:"Grafana Dashboard JSON",filename:"dashboard.json",language:"json",description:"Grafana dashboard for application monitoring",code:'{\n  "dashboard": {\n    "title": "Application Overview",\n    "panels": [\n      {\n        "title": "Request Rate",\n        "type": "graph",\n        "gridPos": {"x": 0, "y": 0, "w": 12, "h": 8},\n        "targets": [{\n          "expr": "sum(rate(http_requests_total[5m])) by (status)",\n          "legendFormat": "{{status}}"\n        }]\n      },\n      {\n        "title": "Response Time (P95)",\n        "type": "gauge",\n        "gridPos": {"x": 12, "y": 0, "w": 6, "h": 8},\n        "targets": [{\n          "expr": "histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket[5m])) by (le))"\n        }],\n        "fieldConfig": {\n          "defaults": {\n            "unit": "s",\n            "thresholds": {\n              "steps": [\n                {"value": 0, "color": "green"},\n                {"value": 0.3, "color": "yellow"},\n                {"value": 0.5, "color": "red"}\n              ]\n            }\n          }\n        }\n      },\n      {\n        "title": "Error Rate",\n        "type": "stat",\n        "gridPos": {"x": 18, "y": 0, "w": 6, "h": 8},\n        "targets": [{\n          "expr": "sum(rate(http_requests_total{status=~\'5..\'}[5m])) / sum(rate(http_requests_total[5m])) * 100"\n        }],\n        "fieldConfig": {\n          "defaults": {\n            "unit": "percent"\n          }\n        }\n      }\n    ]\n  }\n}'}]},{id:"ansible",name:"Ansible",icon:"üîß",color:"#ee0000",flashcards:[{term:"Playbook",definition:"A YAML file containing a series of plays that define automation tasks to be executed on managed hosts."},{term:"Inventory",definition:"A file listing managed hosts and groups, defining which systems Ansible will manage and how to connect."},{term:"Role",definition:"A reusable, self-contained collection of tasks, handlers, variables, and files organized in a defined structure."},{term:"Task",definition:"A single unit of work in Ansible, calling a module with specific arguments to perform an action."},{term:"Module",definition:"Reusable scripts that Ansible runs on managed nodes to perform specific tasks like copying files or installing packages."},{term:"Handler",definition:"A special task that only runs when notified by another task, commonly used for service restarts."},{term:"Vault",definition:"Ansible feature for encrypting sensitive data like passwords and keys within playbooks and files."},{term:"Galaxy",definition:"A hub for finding, sharing, and downloading community-created Ansible roles and collections."}],commands:[{command:"ansible-playbook site.yml",description:"Run a playbook"},{command:"ansible all -m ping",description:"Ping all hosts"},{command:"ansible-vault encrypt file.yml",description:"Encrypt a file"},{command:"ansible-galaxy install role",description:"Install a role from Galaxy"},{command:"ansible-inventory --list",description:"List inventory hosts"}],quiz:[{question:"What file format does Ansible use for playbooks?",options:["JSON","YAML","XML","INI"],correct:1},{question:"What is an Ansible role?",options:["A user account","Reusable collection of tasks","A network configuration","A container"],correct:1},{question:"What is Ansible Vault used for?",options:["Storage","Encrypting sensitive data","Container management","Load balancing"],correct:1},{question:"How does Ansible connect to managed hosts by default?",options:["HTTP","SSH","RDP","FTP"],correct:1}],codebase:[{title:"Ansible Playbook",filename:"site.yml",language:"yaml",description:"Main playbook for deploying a web application",code:'---\n- name: Deploy Web Application\n  hosts: webservers\n  become: yes\n  vars_files:\n    - vars/main.yml\n    - vars/secrets.yml\n\n  pre_tasks:\n    - name: Update apt cache\n      apt:\n        update_cache: yes\n        cache_valid_time: 3600\n\n  roles:\n    - common\n    - nginx\n    - nodejs\n    - app\n\n  tasks:\n    - name: Ensure app directory exists\n      file:\n        path: "{{ app_dir }}"\n        state: directory\n        owner: "{{ app_user }}"\n        mode: \'0755\'\n\n    - name: Deploy application code\n      git:\n        repo: "{{ git_repo }}"\n        dest: "{{ app_dir }}"\n        version: "{{ git_branch }}"\n      notify: Restart application\n\n    - name: Install dependencies\n      npm:\n        path: "{{ app_dir }}"\n        state: present\n\n    - name: Configure environment\n      template:\n        src: templates/env.j2\n        dest: "{{ app_dir }}/.env"\n        mode: \'0600\'\n      notify: Restart application\n\n  handlers:\n    - name: Restart application\n      systemd:\n        name: myapp\n        state: restarted\n        enabled: yes'},{title:"Ansible Role Structure",filename:"roles/app/tasks/main.yml",language:"yaml",description:"Tasks file for application role",code:'---\n- name: Create application user\n  user:\n    name: "{{ app_user }}"\n    shell: /bin/bash\n    home: "/home/{{ app_user }}"\n    create_home: yes\n\n- name: Install application dependencies\n  apt:\n    name:\n      - nodejs\n      - npm\n      - build-essential\n    state: present\n\n- name: Create application directories\n  file:\n    path: "{{ item }}"\n    state: directory\n    owner: "{{ app_user }}"\n    group: "{{ app_user }}"\n    mode: \'0755\'\n  loop:\n    - "{{ app_dir }}"\n    - "{{ app_dir }}/logs"\n    - "{{ app_dir }}/data"\n\n- name: Copy systemd service file\n  template:\n    src: app.service.j2\n    dest: /etc/systemd/system/myapp.service\n  notify:\n    - Reload systemd\n    - Restart application\n\n- name: Ensure application is running\n  systemd:\n    name: myapp\n    state: started\n    enabled: yes'},{title:"Ansible Inventory",filename:"inventory/production.yml",language:"yaml",description:"Dynamic inventory file for production environment",code:"---\nall:\n  vars:\n    ansible_user: deploy\n    ansible_ssh_private_key_file: ~/.ssh/deploy_key\n    ansible_python_interpreter: /usr/bin/python3\n\n  children:\n    webservers:\n      hosts:\n        web1.example.com:\n          nginx_worker_processes: 4\n        web2.example.com:\n          nginx_worker_processes: 4\n      vars:\n        app_port: 3000\n        nginx_enabled: true\n\n    databases:\n      hosts:\n        db1.example.com:\n          postgres_max_connections: 200\n        db2.example.com:\n          postgres_max_connections: 200\n          postgres_role: replica\n      vars:\n        postgres_version: 15\n\n    cache:\n      hosts:\n        redis1.example.com:\n        redis2.example.com:\n      vars:\n        redis_maxmemory: 2gb\n\n    loadbalancers:\n      hosts:\n        lb1.example.com:\n      vars:\n        haproxy_enabled: true"}]},{id:"azure",name:"Azure",icon:"üî∑",color:"#0078d4",flashcards:[{term:"Azure Resource Manager",definition:"The deployment and management service for Azure, providing a management layer for creating, updating, and deleting resources."},{term:"Azure Functions",definition:"A serverless compute service that lets you run event-triggered code without managing infrastructure."},{term:"Azure Kubernetes Service",definition:"A managed Kubernetes container orchestration service to deploy and manage containerized applications."},{term:"Azure DevOps",definition:"A set of development tools for software teams including pipelines, repos, boards, and artifacts."},{term:"Azure Blob Storage",definition:"Object storage solution for storing massive amounts of unstructured data like text or binary data."},{term:"Azure Virtual Network",definition:"A logically isolated network in Azure for securely connecting Azure resources to each other and to on-premises."},{term:"Azure Active Directory",definition:"A cloud-based identity and access management service for signing in and accessing resources."},{term:"Azure Container Registry",definition:"A managed Docker registry service for storing and managing container images."}],commands:[{command:"az login",description:"Login to Azure CLI"},{command:"az group create -n mygroup -l eastus",description:"Create a resource group"},{command:"az aks get-credentials -n cluster -g group",description:"Get AKS credentials"},{command:"az vm list -o table",description:"List VMs in table format"},{command:"az acr build -t image:tag -r registry .",description:"Build container in ACR"}],quiz:[{question:"What is Azure Functions?",options:["Database service","Serverless compute","Container service","Storage service"],correct:1},{question:"What is AKS?",options:["Azure Key Storage","Azure Kubernetes Service","Azure Knowledge System","Azure Kernel Service"],correct:1},{question:"What is Azure Blob Storage used for?",options:["Relational data","Unstructured data","Real-time streams","Container images"],correct:1},{question:"What is Azure DevOps?",options:["A programming language","Development tools suite","A database","A container runtime"],correct:1}],codebase:[{title:"Azure DevOps Pipeline",filename:"azure-pipelines.yml",language:"yaml",description:"Azure DevOps CI/CD pipeline with multi-stage deployment",code:"trigger:\n  branches:\n    include:\n      - main\n      - develop\n\npool:\n  vmImage: 'ubuntu-latest'\n\nvariables:\n  - group: production-secrets\n  - name: imageRepository\n    value: 'myapp'\n  - name: dockerfilePath\n    value: '$(Build.SourcesDirectory)/Dockerfile'\n\nstages:\n  - stage: Build\n    jobs:\n      - job: BuildAndTest\n        steps:\n          - task: NodeTool@0\n            inputs:\n              versionSpec: '20.x'\n          \n          - script: |\n              npm ci\n              npm run lint\n              npm test -- --coverage\n            displayName: 'Install and Test'\n          \n          - task: Docker@2\n            displayName: 'Build and Push Image'\n            inputs:\n              containerRegistry: 'acr-connection'\n              repository: $(imageRepository)\n              command: 'buildAndPush'\n              Dockerfile: $(dockerfilePath)\n              tags: |\n                $(Build.BuildId)\n                latest\n\n  - stage: DeployStaging\n    dependsOn: Build\n    condition: succeeded()\n    jobs:\n      - deployment: DeployToStaging\n        environment: staging\n        strategy:\n          runOnce:\n            deploy:\n              steps:\n                - task: AzureWebAppContainer@1\n                  inputs:\n                    azureSubscription: 'azure-connection'\n                    appName: 'myapp-staging'\n                    imageName: '$(containerRegistry)/$(imageRepository):$(Build.BuildId)'\n\n  - stage: DeployProduction\n    dependsOn: DeployStaging\n    condition: and(succeeded(), eq(variables['Build.SourceBranch'], 'refs/heads/main'))\n    jobs:\n      - deployment: DeployToProduction\n        environment: production\n        strategy:\n          runOnce:\n            deploy:\n              steps:\n                - task: AzureWebAppContainer@1\n                  inputs:\n                    azureSubscription: 'azure-connection'\n                    appName: 'myapp-production'\n                    imageName: '$(containerRegistry)/$(imageRepository):$(Build.BuildId)'"},{title:"ARM Template",filename:"azuredeploy.json",language:"json",description:"Azure Resource Manager template for web app deployment",code:'{\n  "$schema": "https://schema.management.azure.com/schemas/2019-04-01/deploymentTemplate.json#",\n  "contentVersion": "1.0.0.0",\n  "parameters": {\n    "appName": {\n      "type": "string",\n      "metadata": {\n        "description": "Name of the web app"\n      }\n    },\n    "location": {\n      "type": "string",\n      "defaultValue": "[resourceGroup().location]"\n    },\n    "sku": {\n      "type": "string",\n      "defaultValue": "P1v3",\n      "allowedValues": ["F1", "B1", "P1v3", "P2v3"]\n    }\n  },\n  "resources": [\n    {\n      "type": "Microsoft.Web/serverfarms",\n      "apiVersion": "2022-03-01",\n      "name": "[concat(parameters(\'appName\'), \'-plan\')]",\n      "location": "[parameters(\'location\')]",\n      "sku": {\n        "name": "[parameters(\'sku\')]"\n      },\n      "kind": "linux",\n      "properties": {\n        "reserved": true\n      }\n    },\n    {\n      "type": "Microsoft.Web/sites",\n      "apiVersion": "2022-03-01",\n      "name": "[parameters(\'appName\')]",\n      "location": "[parameters(\'location\')]",\n      "dependsOn": [\n        "[resourceId(\'Microsoft.Web/serverfarms\', concat(parameters(\'appName\'), \'-plan\'))]"\n      ],\n      "properties": {\n        "serverFarmId": "[resourceId(\'Microsoft.Web/serverfarms\', concat(parameters(\'appName\'), \'-plan\'))]",\n        "siteConfig": {\n          "linuxFxVersion": "NODE|20-lts",\n          "alwaysOn": true\n        },\n        "httpsOnly": true\n      }\n    }\n  ],\n  "outputs": {\n    "appUrl": {\n      "type": "string",\n      "value": "[concat(\'https://\', parameters(\'appName\'), \'.azurewebsites.net\')]"\n    }\n  }\n}'}]},{id:"devsecops",name:"DevSecOps",icon:"üîí",color:"#dc2626",flashcards:[{term:"Shift Left Security",definition:"The practice of integrating security earlier in the software development lifecycle rather than at the end."},{term:"SAST",definition:"Static Application Security Testing - Analyzing source code for security vulnerabilities without executing the program."},{term:"DAST",definition:"Dynamic Application Security Testing - Testing running applications to find vulnerabilities by simulating attacks."},{term:"Container Scanning",definition:"Analyzing container images for known vulnerabilities in OS packages and application dependencies."},{term:"Secret Management",definition:"Securely storing, distributing, and rotating sensitive data like API keys, passwords, and certificates."},{term:"OWASP Top 10",definition:"A standard awareness document listing the most critical security risks to web applications."},{term:"Dependency Scanning",definition:"Automated checking of third-party libraries and dependencies for known security vulnerabilities."},{term:"Infrastructure Scanning",definition:"Analyzing IaC templates and cloud configurations for security misconfigurations and compliance issues."}],commands:[{command:"trivy image myimage:tag",description:"Scan container for vulnerabilities"},{command:"snyk test",description:"Test project dependencies for vulnerabilities"},{command:"gitleaks detect",description:"Detect secrets in git repos"},{command:"checkov -f main.tf",description:"Scan Terraform for misconfigurations"},{command:"tfsec .",description:"Security scanner for Terraform"}],quiz:[{question:'What does "Shift Left" mean in DevSecOps?',options:["Move to cloud","Integrate security early","Use left-aligned code","Deploy faster"],correct:1},{question:"What is SAST?",options:["Simple Auth Service","Static Application Security Testing","Server Authentication","System Admin Tool"],correct:1},{question:"What does Trivy scan for?",options:["Performance issues","Container vulnerabilities","Network traffic","User activity"],correct:1},{question:"What is the OWASP Top 10?",options:["Best frameworks","Critical web security risks","Programming languages","Cloud providers"],correct:1}],codebase:[{title:"Security Scanning Pipeline",filename:".github/workflows/security.yml",language:"yaml",description:"GitHub Actions workflow for comprehensive security scanning",code:"name: Security Scan\n\non:\n  push:\n    branches: [main]\n  pull_request:\n    branches: [main]\n  schedule:\n    - cron: '0 0 * * *'\n\njobs:\n  dependency-scan:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      \n      - name: Run Snyk to check for vulnerabilities\n        uses: snyk/actions/node@master\n        env:\n          SNYK_TOKEN: ${{ secrets.SNYK_TOKEN }}\n        with:\n          args: --severity-threshold=high\n\n  sast:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      \n      - name: Run Semgrep\n        uses: returntocorp/semgrep-action@v1\n        with:\n          config: p/owasp-top-ten\n\n  container-scan:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      \n      - name: Build image\n        run: docker build -t myapp:test .\n      \n      - name: Run Trivy vulnerability scanner\n        uses: aquasecurity/trivy-action@master\n        with:\n          image-ref: 'myapp:test'\n          format: 'sarif'\n          output: 'trivy-results.sarif'\n          severity: 'CRITICAL,HIGH'\n\n  secret-scan:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n        with:\n          fetch-depth: 0\n      \n      - name: Detect secrets with Gitleaks\n        uses: gitleaks/gitleaks-action@v2\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n\n  iac-scan:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      \n      - name: Run Checkov\n        uses: bridgecrewio/checkov-action@master\n        with:\n          directory: terraform/\n          framework: terraform"},{title:"Trivy Configuration",filename:"trivy.yaml",language:"yaml",description:"Trivy scanner configuration for container security",code:"# trivy.yaml - Trivy configuration file\nseverity:\n  - CRITICAL\n  - HIGH\n  - MEDIUM\n\nvuln-type:\n  - os\n  - library\n\nignore-unfixed: true\n\nexit-code: 1\n\nformat: table\n\n# Ignore specific CVEs if needed\nignorefile: .trivyignore\n\n# Scan configuration\nscan:\n  # Skip directories\n  skip-dirs:\n    - node_modules\n    - vendor\n    - .git\n  \n  # Security checks to enable\n  security-checks:\n    - vuln\n    - config\n    - secret\n\n# Misconfig scanning options\nmisconfiguration:\n  # Policy paths\n  policy-paths:\n    - ./policies\n  \n  # Include successes in report\n  include-successes: false\n\n# Cache settings\ncache:\n  dir: /tmp/trivy-cache\n  clear: false"},{title:"OWASP Security Headers",filename:"security-headers.conf",language:"nginx",description:"Nginx security headers configuration following OWASP guidelines",code:"# Security Headers Configuration\n\n# Prevent clickjacking\nadd_header X-Frame-Options \"SAMEORIGIN\" always;\n\n# Prevent MIME type sniffing\nadd_header X-Content-Type-Options \"nosniff\" always;\n\n# Enable XSS filter\nadd_header X-XSS-Protection \"1; mode=block\" always;\n\n# Referrer policy\nadd_header Referrer-Policy \"strict-origin-when-cross-origin\" always;\n\n# Content Security Policy\nadd_header Content-Security-Policy \"default-src 'self'; script-src 'self' 'unsafe-inline'; style-src 'self' 'unsafe-inline'; img-src 'self' data: https:; font-src 'self'; connect-src 'self' https://api.example.com; frame-ancestors 'self';\" always;\n\n# Permissions Policy\nadd_header Permissions-Policy \"accelerometer=(), camera=(), geolocation=(), gyroscope=(), magnetometer=(), microphone=(), payment=(), usb=()\" always;\n\n# HSTS - Strict Transport Security\nadd_header Strict-Transport-Security \"max-age=31536000; includeSubDomains; preload\" always;\n\n# Remove server header\nserver_tokens off;\n\n# SSL configuration\nssl_protocols TLSv1.2 TLSv1.3;\nssl_ciphers ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256;\nssl_prefer_server_ciphers off;\nssl_session_timeout 1d;\nssl_session_cache shared:SSL:50m;\nssl_stapling on;\nssl_stapling_verify on;"}]},{id:"networking",name:"Networking",icon:"üåê",color:"#0891b2",flashcards:[{term:"TCP/IP",definition:"The fundamental communication protocol suite of the internet, providing end-to-end data communication."},{term:"DNS",definition:"Domain Name System - Translates human-readable domain names to IP addresses that computers use."},{term:"Load Balancer",definition:"Distributes incoming network traffic across multiple servers to ensure availability and reliability."},{term:"Reverse Proxy",definition:"A server that sits in front of web servers, forwarding client requests to appropriate backend servers."},{term:"CIDR",definition:"Classless Inter-Domain Routing - A method for allocating IP addresses and IP routing."},{term:"SSL/TLS",definition:"Cryptographic protocols providing secure communication over a computer network through encryption."},{term:"Firewall",definition:"A network security system that monitors and controls incoming and outgoing network traffic."},{term:"NAT",definition:"Network Address Translation - Maps private IP addresses to public IP addresses for internet access."}],commands:[{command:"curl -v https://example.com",description:"Make HTTP request with verbose output"},{command:"nslookup domain.com",description:"Query DNS for domain"},{command:"netstat -tulpn",description:"Show listening ports"},{command:"traceroute example.com",description:"Trace packet route to host"},{command:"ss -tunlp",description:"Show socket statistics"}],quiz:[{question:"What does DNS translate?",options:["IP to MAC","Domain names to IPs","Ports to services","HTTP to HTTPS"],correct:1},{question:"What is a load balancer used for?",options:["Encryption","Distributing traffic","DNS resolution","File storage"],correct:1},{question:"What does CIDR stand for?",options:["Cloud Internet Domain Routing","Classless Inter-Domain Routing","Central IP Data Registry","Cluster IP Distribution Rule"],correct:1},{question:"What does NAT do?",options:["Encrypts traffic","Maps private to public IPs","Balances load","Resolves DNS"],correct:1}],codebase:[{title:"Nginx Reverse Proxy",filename:"nginx.conf",language:"nginx",description:"Nginx configuration for reverse proxy with load balancing",code:'upstream backend {\n    least_conn;\n    server app1:3000 weight=3;\n    server app2:3000 weight=2;\n    server app3:3000 backup;\n    \n    keepalive 32;\n}\n\nserver {\n    listen 80;\n    server_name example.com;\n    return 301 https://$server_name$request_uri;\n}\n\nserver {\n    listen 443 ssl http2;\n    server_name example.com;\n\n    ssl_certificate /etc/ssl/certs/example.com.crt;\n    ssl_certificate_key /etc/ssl/private/example.com.key;\n\n    # Logging\n    access_log /var/log/nginx/access.log;\n    error_log /var/log/nginx/error.log;\n\n    # Proxy settings\n    location / {\n        proxy_pass http://backend;\n        proxy_http_version 1.1;\n        proxy_set_header Upgrade $http_upgrade;\n        proxy_set_header Connection \'upgrade\';\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header X-Forwarded-Proto $scheme;\n        proxy_cache_bypass $http_upgrade;\n        \n        proxy_connect_timeout 60s;\n        proxy_send_timeout 60s;\n        proxy_read_timeout 60s;\n    }\n\n    # Static files\n    location /static/ {\n        alias /var/www/static/;\n        expires 30d;\n        add_header Cache-Control "public, immutable";\n    }\n\n    # Health check endpoint\n    location /health {\n        access_log off;\n        return 200 "OK";\n    }\n}'},{title:"HAProxy Configuration",filename:"haproxy.cfg",language:"haproxy",description:"HAProxy load balancer configuration with health checks",code:"global\n    log stdout format raw local0\n    maxconn 4096\n    tune.ssl.default-dh-param 2048\n\ndefaults\n    mode http\n    log global\n    option httplog\n    option dontlognull\n    option http-server-close\n    option forwardfor except 127.0.0.0/8\n    option redispatch\n    retries 3\n    timeout connect 5s\n    timeout client 30s\n    timeout server 30s\n    timeout http-keep-alive 10s\n    timeout check 5s\n\nfrontend http_front\n    bind *:80\n    redirect scheme https code 301 if !{ ssl_fc }\n\nfrontend https_front\n    bind *:443 ssl crt /etc/ssl/certs/combined.pem\n    \n    # ACLs for routing\n    acl is_api path_beg /api\n    acl is_ws hdr(Upgrade) -i websocket\n    \n    use_backend api_servers if is_api\n    use_backend ws_servers if is_ws\n    default_backend web_servers\n\nbackend web_servers\n    balance roundrobin\n    option httpchk GET /health\n    http-check expect status 200\n    \n    server web1 10.0.1.10:3000 check inter 5s fall 3 rise 2\n    server web2 10.0.1.11:3000 check inter 5s fall 3 rise 2\n    server web3 10.0.1.12:3000 check inter 5s fall 3 rise 2 backup\n\nbackend api_servers\n    balance leastconn\n    option httpchk GET /api/health\n    \n    server api1 10.0.2.10:8080 check\n    server api2 10.0.2.11:8080 check\n\nbackend ws_servers\n    balance source\n    server ws1 10.0.3.10:9000 check\n    server ws2 10.0.3.11:9000 check\n\nlisten stats\n    bind *:8404\n    stats enable\n    stats uri /stats\n    stats refresh 10s\n    stats admin if LOCALHOST"},{title:"iptables Firewall Rules",filename:"firewall.sh",language:"bash",description:"Linux iptables firewall configuration script",code:'#!/bin/bash\n# Firewall configuration script\n\n# Flush existing rules\niptables -F\niptables -X\niptables -t nat -F\niptables -t nat -X\n\n# Set default policies\niptables -P INPUT DROP\niptables -P FORWARD DROP\niptables -P OUTPUT ACCEPT\n\n# Allow loopback\niptables -A INPUT -i lo -j ACCEPT\niptables -A OUTPUT -o lo -j ACCEPT\n\n# Allow established connections\niptables -A INPUT -m conntrack --ctstate ESTABLISHED,RELATED -j ACCEPT\n\n# Allow SSH (rate limited)\niptables -A INPUT -p tcp --dport 22 -m conntrack --ctstate NEW -m limit --limit 3/min --limit-burst 3 -j ACCEPT\n\n# Allow HTTP/HTTPS\niptables -A INPUT -p tcp --dport 80 -j ACCEPT\niptables -A INPUT -p tcp --dport 443 -j ACCEPT\n\n# Allow ping (limited)\niptables -A INPUT -p icmp --icmp-type echo-request -m limit --limit 1/s --limit-burst 4 -j ACCEPT\n\n# Drop invalid packets\niptables -A INPUT -m conntrack --ctstate INVALID -j DROP\n\n# Log dropped packets\niptables -A INPUT -j LOG --log-prefix "DROPPED: " --log-level 4\n\n# Save rules\niptables-save > /etc/iptables/rules.v4\n\necho "Firewall rules applied"'}]}]};let state={currentTopic:null,currentView:"welcome",currentTab:"flashcards",currentCardIndex:0,currentQuestionIndex:0,quizScore:0,quizAnswered:!1,isCardFlipped:!1,progress:{}};function loadProgress(){const e=localStorage.getItem("devops-mastery-progress");e?state.progress=JSON.parse(e):devopsData.topics.forEach(e=>{state.progress[e.id]={flashcardsViewed:[],quizBestScore:0,quizAttempts:0}})}function saveProgress(){localStorage.setItem("devops-mastery-progress",JSON.stringify(state.progress)),updateHeaderStats()}function calculateOverallProgress(){let e=0,n=0;return devopsData.topics.forEach(t=>{e+=t.flashcards.length,state.progress[t.id]&&(n+=state.progress[t.id].flashcardsViewed.length)}),e>0?Math.round(n/e*100):0}function calculateTopicProgress(e){const n=devopsData.topics.find(n=>n.id===e);if(!n||!state.progress[e])return 0;const t=state.progress[e].flashcardsViewed.length/n.flashcards.length*50,i=state.progress[e].quizBestScore/n.quiz.length*50;return Math.round(t+i)}function updateHeaderStats(){const e=calculateOverallProgress();let n=0;Object.values(state.progress).forEach(e=>{n+=e.flashcardsViewed.length}),document.getElementById("totalProgress").textContent=e+"%",document.getElementById("cardsStudied").textContent=n}function renderSidebarTopics(){const e=document.getElementById("topicList");e.innerHTML="",devopsData.topics.forEach(n=>{const t=calculateTopicProgress(n.id),i=document.createElement("li");i.className="topic-item "+(state.currentTopic?.id===n.id?"active":""),i.style.setProperty("--topic-color",n.color),i.innerHTML=`\n            <span class="topic-icon">${n.icon}</span>\n            <span class="topic-name">${n.name}</span>\n            <div class="topic-progress">\n                <div class="topic-progress-fill" style="width: ${t}%"></div>\n            </div>\n        `,i.addEventListener("click",()=>selectTopic(n)),e.appendChild(i)})}function renderTopicGrid(){const e=document.getElementById("topicGrid");e.innerHTML="",devopsData.topics.forEach(n=>{const t=calculateTopicProgress(n.id),i=document.createElement("div");i.className="topic-card",i.style.setProperty("--card-color",n.color),i.innerHTML=`\n            <span class="topic-card-icon">${n.icon}</span>\n            <h3 class="topic-card-name">${n.name}</h3>\n            <div class="topic-card-stats">\n                <span>üìá ${n.flashcards.length} cards</span>\n                <span>‚ùì ${n.quiz.length} questions</span>\n            </div>\n            <div class="topic-card-progress">\n                <div class="topic-card-progress-fill" style="width: ${t}%"></div>\n            </div>\n        `,i.addEventListener("click",()=>selectTopic(n)),e.appendChild(i)})}function selectTopic(e){state.currentTopic=e,state.currentCardIndex=0,state.currentQuestionIndex=0,state.quizScore=0,state.isCardFlipped=!1,document.getElementById("welcomeScreen").classList.add("hidden"),document.getElementById("studyArea").classList.remove("hidden"),document.getElementById("currentTopicIcon").textContent=e.icon,document.getElementById("currentTopicName").textContent=e.name,state.currentTab="flashcards",updateTabs(),renderFlashcard(),renderSidebarTopics()}function goBack(){state.currentTopic=null,state.currentView="welcome",document.getElementById("welcomeScreen").classList.remove("hidden"),document.getElementById("studyArea").classList.add("hidden"),renderSidebarTopics()}function updateTabs(){document.querySelectorAll(".tab-btn").forEach(e=>{e.classList.toggle("active",e.dataset.tab===state.currentTab)});const e=document.getElementById("flashcardView"),n=document.getElementById("quizView"),t=document.getElementById("quizResults"),i=document.getElementById("commandsView"),o=document.getElementById("matchView"),r=document.getElementById("codebaseView");e.classList.toggle("hidden","flashcards"!==state.currentTab),n.classList.toggle("hidden","quiz"!==state.currentTab),i.classList.toggle("hidden","commands"!==state.currentTab),o.classList.toggle("hidden","match"!==state.currentTab),r.classList.toggle("hidden","codebase"!==state.currentTab),t.classList.add("hidden"),"quiz"===state.currentTab&&(state.currentQuestionIndex=0,state.quizScore=0,state.quizAnswered=!1,renderQuizQuestion()),"commands"===state.currentTab&&renderCommands(),"match"===state.currentTab&&initMatchGame(),"codebase"===state.currentTab&&renderCodebase()}function renderCodebase(){if(!state.currentTopic)return;const e=state.currentTopic.codebase||[],n=document.getElementById("codebaseList");n.innerHTML="",0!==e.length?e.forEach((e,t)=>{const i=document.createElement("div");i.className="codebase-item",i.innerHTML=`\n            <div class="codebase-item-header">\n                <div class="codebase-item-title">\n                    <span class="file-icon">üìÑ</span>\n                    <span>${e.title}</span>\n                    <span class="file-name">${e.filename}</span>\n                </div>\n                <span class="codebase-item-badge">${e.language}</span>\n            </div>\n            <div class="codebase-item-description">${e.description}</div>\n            <div class="codebase-item-code">\n                <button class="codebase-copy-btn" onclick="copyCodebase(${t})">üìã Copy</button>\n                <pre><code>${escapeHtml(e.code)}</code></pre>\n            </div>\n        `,n.appendChild(i)}):n.innerHTML='<p style="color: var(--text-tertiary); text-align: center; padding: 2rem;">No code examples available for this topic yet.</p>'}function escapeHtml(e){const n=document.createElement("div");return n.textContent=e,n.innerHTML}function copyCodebase(e){const n=state.currentTopic.codebase||[];n[e]&&navigator.clipboard.writeText(n[e].code).then(()=>{const n=document.querySelectorAll(".codebase-copy-btn");if(n[e]){const t=n[e].textContent;n[e].textContent="‚úì Copied!",setTimeout(()=>{n[e].textContent=t},1500)}})}function renderCommands(){if(!state.currentTopic)return;const e=state.currentTopic.commands||[],n=document.getElementById("commandsList");n.innerHTML="",0!==e.length?e.forEach(e=>{const t=document.createElement("div");t.className="command-item",t.innerHTML=`\n            <button class="command-copy-btn" onclick="copyCommand('${e.command.replace(/'/g,"\\'")}')">üìã Copy</button>\n            <code class="command-code">${e.command}</code>\n            <p class="command-description">${e.description}</p>\n        `,n.appendChild(t)}):n.innerHTML='<p style="color: var(--text-tertiary); text-align: center; padding: 2rem;">No commands available for this topic yet.</p>'}function copyCommand(e){navigator.clipboard.writeText(e).then(()=>{const e=event.target,n=e.textContent;e.textContent="‚úì Copied!",setTimeout(()=>{e.textContent=n},1500)})}let matchState={pairs:[],selectedTerm:null,matchedPairs:0,attempts:0,startTime:null,timerInterval:null};function shuffleArray(e){const n=[...e];for(let e=n.length-1;e>0;e--){const t=Math.floor(Math.random()*(e+1));[n[e],n[t]]=[n[t],n[e]]}return n}function initMatchGame(){if(!state.currentTopic)return;matchState={pairs:[],selectedTerm:null,matchedPairs:0,attempts:0,startTime:Date.now(),timerInterval:null};const e=state.currentTopic.flashcards,n=shuffleArray(e).slice(0,Math.min(6,e.length));matchState.pairs=n.map((e,n)=>({id:n,term:e.term,definition:e.definition.length>100?e.definition.substring(0,100)+"...":e.definition,matched:!1})),document.getElementById("totalPairs").textContent=matchState.pairs.length,document.getElementById("matchedPairs").textContent="0",document.getElementById("matchAttempts").textContent="0",document.getElementById("matchComplete").classList.add("hidden"),renderMatchItems(),matchState.timerInterval&&clearInterval(matchState.timerInterval),matchState.timerInterval=setInterval(updateMatchTimer,1e3),updateMatchTimer()}function renderMatchItems(){const e=document.getElementById("matchTerms"),n=document.getElementById("matchDefinitions"),t=shuffleArray(matchState.pairs),i=shuffleArray(matchState.pairs);e.innerHTML="",n.innerHTML="",t.forEach(n=>{const t=document.createElement("div");t.className="match-item term "+(n.matched?"matched":""),t.dataset.id=n.id,t.dataset.type="term",t.textContent=n.term,n.matched||t.addEventListener("click",()=>selectMatchItem(t,n.id,"term")),e.appendChild(t)}),i.forEach(e=>{const t=document.createElement("div");t.className="match-item definition "+(e.matched?"matched":""),t.dataset.id=e.id,t.dataset.type="definition",t.textContent=e.definition,e.matched||t.addEventListener("click",()=>selectMatchItem(t,e.id,"definition")),n.appendChild(t)})}function selectMatchItem(e,n,t){if(!e.classList.contains("matched"))if("term"===t)document.querySelectorAll(".match-item.term.selected").forEach(e=>{e.classList.remove("selected")}),e.classList.add("selected"),matchState.selectedTerm=n;else if("definition"===t&&null!==matchState.selectedTerm)if(matchState.attempts++,document.getElementById("matchAttempts").textContent=matchState.attempts,matchState.selectedTerm===n)matchState.pairs[n].matched=!0,matchState.matchedPairs++,document.getElementById("matchedPairs").textContent=matchState.matchedPairs,document.querySelectorAll(`.match-item[data-id="${n}"]`).forEach(e=>{e.classList.remove("selected"),e.classList.add("matched")}),matchState.selectedTerm=null,matchState.matchedPairs===matchState.pairs.length&&endMatchGame();else{e.classList.add("incorrect");const n=document.querySelector(".match-item.term.selected");n&&n.classList.add("incorrect"),setTimeout(()=>{e.classList.remove("incorrect"),n&&n.classList.remove("incorrect","selected"),matchState.selectedTerm=null},500)}}function updateMatchTimer(){if(!matchState.startTime)return;const e=Math.floor((Date.now()-matchState.startTime)/1e3),n=Math.floor(e/60),t=e%60;document.getElementById("matchTimer").textContent=`${n}:${t.toString().padStart(2,"0")}`}function endMatchGame(){clearInterval(matchState.timerInterval);const e=Math.floor((Date.now()-matchState.startTime)/1e3),n=Math.floor(e/60),t=e%60;document.getElementById("matchFinalTime").textContent=`${n}:${t.toString().padStart(2,"0")}`,document.getElementById("matchFinalAttempts").textContent=matchState.attempts,document.getElementById("matchComplete").classList.remove("hidden")}function restartMatchGame(){matchState.timerInterval&&clearInterval(matchState.timerInterval),initMatchGame()}function renderFlashcard(){if(!state.currentTopic)return;const e=state.currentTopic.flashcards,n=e[state.currentCardIndex];document.getElementById("flashcardTerm").textContent=n.term,document.getElementById("flashcardDefinition").textContent=n.definition,document.getElementById("currentCardNum").textContent=state.currentCardIndex+1,document.getElementById("totalCards").textContent=e.length;const t=(state.currentCardIndex+1)/e.length*100;document.getElementById("flashcardProgress").style.width=t+"%",document.getElementById("flashcard").classList.remove("flipped"),state.isCardFlipped=!1,document.getElementById("prevCard").disabled=0===state.currentCardIndex,document.getElementById("nextCard").disabled=state.currentCardIndex===e.length-1,markCardViewed(state.currentTopic.id,state.currentCardIndex)}function markCardViewed(e,n){state.progress[e]||(state.progress[e]={flashcardsViewed:[],quizBestScore:0,quizAttempts:0}),state.progress[e].flashcardsViewed.includes(n)||(state.progress[e].flashcardsViewed.push(n),saveProgress(),renderSidebarTopics())}function flipCard(){document.getElementById("flashcard").classList.toggle("flipped"),state.isCardFlipped=!state.isCardFlipped}function prevCard(){state.currentCardIndex>0&&(state.currentCardIndex--,renderFlashcard())}function nextCard(){state.currentCardIndex<state.currentTopic.flashcards.length-1&&(state.currentCardIndex++,renderFlashcard())}function renderQuizQuestion(){if(!state.currentTopic)return;const e=state.currentTopic.quiz,n=e[state.currentQuestionIndex];document.getElementById("quizQuestion").textContent=n.question,document.getElementById("currentQuestionNum").textContent=state.currentQuestionIndex+1,document.getElementById("totalQuestions").textContent=e.length,document.getElementById("quizScore").textContent=state.quizScore;const t=document.getElementById("quizOptions");t.innerHTML="";const i=["A","B","C","D"];n.options.forEach((e,n)=>{const o=document.createElement("button");o.className="quiz-option",o.innerHTML=`\n            <span class="option-letter">${i[n]}</span>\n            <span>${e}</span>\n        `,o.addEventListener("click",()=>selectAnswer(n)),t.appendChild(o)});const o=(state.currentQuestionIndex+1)/e.length*100;document.getElementById("quizProgress").style.width=o+"%",document.getElementById("quizFeedback").classList.add("hidden"),document.getElementById("quizNextBtn").classList.add("hidden"),state.quizAnswered=!1}function selectAnswer(e){if(state.quizAnswered)return;state.quizAnswered=!0;const n=state.currentTopic.quiz[state.currentQuestionIndex],t=e===n.correct;t&&(state.quizScore++,document.getElementById("quizScore").textContent=state.quizScore);document.querySelectorAll(".quiz-option").forEach((i,o)=>{i.disabled=!0,o===n.correct?i.classList.add("correct"):o!==e||t||i.classList.add("incorrect")});const i=document.getElementById("quizFeedback"),o=document.getElementById("feedbackText");i.classList.remove("hidden","correct","incorrect"),i.classList.add(t?"correct":"incorrect"),o.textContent=t?"‚úì Correct! Well done!":`‚úó Incorrect. The correct answer is: ${n.options[n.correct]}`,document.getElementById("quizNextBtn").classList.remove("hidden")}function nextQuizQuestion(){state.currentQuestionIndex<state.currentTopic.quiz.length-1?(state.currentQuestionIndex++,renderQuizQuestion()):showQuizResults()}function showQuizResults(){const e=document.getElementById("quizView"),n=document.getElementById("quizResults");e.classList.add("hidden"),n.classList.remove("hidden");const t=state.currentTopic.quiz.length,i=Math.round(state.quizScore/t*100);document.getElementById("finalScore").textContent=state.quizScore,document.getElementById("maxScore").textContent=t,document.getElementById("resultsPercentage").textContent=i+"%";const o=document.getElementById("resultsIcon"),r=document.getElementById("resultsTitle");i>=80?(o.textContent="üéâ",r.textContent="Excellent Work!"):i>=60?(o.textContent="üëç",r.textContent="Good Job!"):i>=40?(o.textContent="üìö",r.textContent="Keep Studying!"):(o.textContent="üí™",r.textContent="Practice Makes Perfect!"),state.progress[state.currentTopic.id]||(state.progress[state.currentTopic.id]={flashcardsViewed:[],quizBestScore:0,quizAttempts:0}),state.quizScore>state.progress[state.currentTopic.id].quizBestScore&&(state.progress[state.currentTopic.id].quizBestScore=state.quizScore),state.progress[state.currentTopic.id].quizAttempts++,saveProgress(),renderSidebarTopics()}function retryQuiz(){state.currentQuestionIndex=0,state.quizScore=0,state.quizAnswered=!1,document.getElementById("quizResults").classList.add("hidden"),document.getElementById("quizView").classList.remove("hidden"),renderQuizQuestion()}function studyCards(){state.currentTab="flashcards",state.currentCardIndex=0,document.getElementById("quizResults").classList.add("hidden"),updateTabs(),renderFlashcard()}function handleSearch(e){const n=e.target.value.toLowerCase().trim();if(!n)return void renderTopicGrid();const t=[];devopsData.topics.forEach(e=>{const i=e.name.toLowerCase().includes(n),o=e.flashcards.filter(e=>e.term.toLowerCase().includes(n)||e.definition.toLowerCase().includes(n));(i||o.length>0)&&t.push({topic:e,matchCount:o.length+(i?1:0)})});const i=document.getElementById("topicGrid");i.innerHTML="",0!==t.length?t.forEach(({topic:e})=>{const n=calculateTopicProgress(e.id),t=document.createElement("div");t.className="topic-card",t.style.setProperty("--card-color",e.color),t.innerHTML=`\n            <span class="topic-card-icon">${e.icon}</span>\n            <h3 class="topic-card-name">${e.name}</h3>\n            <div class="topic-card-stats">\n                <span>üìá ${e.flashcards.length} cards</span>\n                <span>‚ùì ${e.quiz.length} questions</span>\n            </div>\n            <div class="topic-card-progress">\n                <div class="topic-card-progress-fill" style="width: ${n}%"></div>\n            </div>\n        `,t.addEventListener("click",()=>selectTopic(e)),i.appendChild(t)}):i.innerHTML='<p style="color: var(--text-tertiary); grid-column: 1/-1; text-align: center; padding: 2rem;">No results found</p>'}function init(){loadProgress(),renderSidebarTopics(),renderTopicGrid(),updateHeaderStats(),document.getElementById("backBtn").addEventListener("click",goBack),document.getElementById("flashcard").addEventListener("click",flipCard),document.getElementById("prevCard").addEventListener("click",prevCard),document.getElementById("nextCard").addEventListener("click",nextCard),document.getElementById("quizNextBtn").addEventListener("click",nextQuizQuestion),document.getElementById("retryQuizBtn").addEventListener("click",retryQuiz),document.getElementById("studyCardsBtn").addEventListener("click",studyCards),document.getElementById("searchInput").addEventListener("input",handleSearch),document.getElementById("matchRestartBtn").addEventListener("click",restartMatchGame),document.getElementById("matchPlayAgainBtn").addEventListener("click",restartMatchGame),document.querySelectorAll(".tab-btn").forEach(e=>{e.addEventListener("click",()=>{state.currentTab=e.dataset.tab,updateTabs(),"flashcards"===state.currentTab&&renderFlashcard()})}),document.addEventListener("keydown",e=>{state.currentTopic&&"flashcards"===state.currentTab&&("ArrowLeft"===e.key&&prevCard(),"ArrowRight"===e.key&&nextCard()," "!==e.key&&"Enter"!==e.key||(e.preventDefault(),flipCard()))})}document.addEventListener("DOMContentLoaded",init);